{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoder Distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from transformers import (SamModel, SamProcessor)\n",
    "from utils.mobile_sam import sam_model_registry\n",
    "from utils.mobile_sam.predictor import SamPredictor\n",
    "\n",
    "from utils.datasets import SA1B_Dataset\n",
    "from utils.utils import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "DATA_DIR = Path('../Datasets/')\n",
    "GPU = 3\n",
    "\n",
    "DEVICE = torch.device(f\"cuda:{GPU}\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "dataset = SA1B_Dataset(root=DATA_DIR.joinpath('SA_1B/images/'), features=None, split='sa_000009')\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, (i, l, n) in enumerate(dataloader):\n",
    "    print(i.shape, l.shape, n)\n",
    "    if j > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(l.unique()))\n",
    "plt.imshow(l[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teacher\n",
    "teacher = SamModel.from_pretrained(\"facebook/sam-vit-huge\").to(DEVICE).eval()\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Student\n",
    "model_type = \"vit_t\"\n",
    "sam_checkpoint = \"bin/mobile_sam.pt\"\n",
    "\n",
    "model = sam_model_registry[model_type](checkpoint=None).to(DEVICE).train()\n",
    "student = SamPredictor(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    inputs = processor(i, input_points=None, return_tensors=\"pt\").to(DEVICE)\n",
    "    t_features = teacher.get_image_embeddings(inputs[\"pixel_values\"]).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mse\n",
    "mse = torch.nn.MSELoss()\n",
    "mse(t_features, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Distiller():\n",
    "    def __init__(self, teacher, student, processor, dataloader, optimizer, device):\n",
    "        self.teacher = teacher\n",
    "        self.student = student\n",
    "        self.processor = processor\n",
    "        self.dataloader = dataloader\n",
    "        self.optimizer = optimizer\n",
    "        self.device = device\n",
    "\n",
    "    def get_distillation_loss(self, img):\n",
    "        student.set_image(img[0].permute((2,0,1)))\n",
    "        s_features = student.features\n",
    "\n",
    "        with torch.no_grad():\n",
    "            inputs = processor(img, input_points=None, return_tensors=\"pt\").to(DEVICE)\n",
    "            t_features = teacher.get_image_embeddings(inputs[\"pixel_values\"])\n",
    "\n",
    "        return torch.nn.functional.mse_loss(s_features, t_features)\n",
    "\n",
    "    def distill(self):\n",
    "        t = tqdm(dataloader, desc='Distillation:')\n",
    "        for img, _, _ in t:\n",
    "            self.optimizer.zero_grad()\n",
    "            loss = self.get_distillation_loss(img)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            t.set_postfix({'Loss': loss.item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(student.model.parameters(), lr=1e-3)\n",
    "distiller = Distiller(teacher, student, processor, dataloader, optimizer, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distiller.distill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(distiller.student.model.state_dict(), 'bin/distilled_mobile_sam.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_features_ids = csv.reader(open(Path('results/feature_ids.csv'), 'r'))\n",
    "l = list(teacher_features_ids)\n",
    "#l = [i[0] for i in l]\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = torch.load('results/teacher_features.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decoder Distillation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- prompt a random point belonging to an instance\n",
    "- get the corresponding mask and mask size\n",
    "- use saved SAM features\n",
    "- freeze MobileSAM backbone\n",
    "- prompt SAM and MobileSAM and collect output masks (3 masks?)\n",
    "- compute dice and focal loss (20:1)\n",
    "- weight loss based on mask size\n",
    "- OBTAIN LOGITS FROM (MOBILESAM, SAM) !!! (return_logits=True, binarize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_prompt()\n",
    "# get_instance_label()\n",
    "# get_mask_size()\n",
    "# size coefficient = 1 - (mask_size / image_size)\n",
    "#Â get_output(SAM, saved_features, prompt)\n",
    "# get_output(MobileSAM, saved_features, prompt) \n",
    "# dice_loss()\n",
    "# focal_loss()\n",
    "# loss = (20 * dice_loss() + focal_loss()) * size_coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from distillation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path('../Datasets/')\n",
    "SPLIT = 'sa_000020'\n",
    "GPU = 2\n",
    "DEVICE = torch.device(f\"cuda:{GPU}\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "SHUFFLE = True\n",
    "LOAD_FEATURES = True\n",
    "FEATURES = 'results/teacher_features.pt' if LOAD_FEATURES else None\n",
    "\n",
    "EPOCHS = 16\n",
    "LR = 1e-3\n",
    "OPTIM = 'adamw'\n",
    "WD = 1e-5\n",
    "LOSS_WEIGHTS = [0,0,1,0] # 20 focal, 1 dice, 0 bce, 0 size\n",
    "\n",
    "MODE = 'decoder' # encoder, decoder, save_features\n",
    "PRETRAINED = True if MODE == 'decoder' else False\n",
    "\n",
    "dataset = SA1B_Dataset(root=DATA_DIR.joinpath('SA_1B/images/'), split=SPLIT,  features=FEATURES, labels=True)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=SHUFFLE, num_workers=16, pin_memory=True)\n",
    "\n",
    "teacher = SamModel.from_pretrained(\"facebook/sam-vit-huge\").to(DEVICE)\n",
    "teacher.eval()\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")\n",
    "\n",
    "model_type = \"vit_t\"\n",
    "sam_checkpoint = \"bin/mobile_sam.pt\" if PRETRAINED else None\n",
    "\n",
    "model = sam_model_registry[model_type](checkpoint=sam_checkpoint).to(DEVICE)\n",
    "model.eval()\n",
    "for m in model.image_encoder.modules():\n",
    "    if isinstance(m, torch.nn.BatchNorm2d):\n",
    "        m.eval()\n",
    "        m.weight.requires_grad_(False)\n",
    "        m.bias.requires_grad_(False)\n",
    "student = SamPredictor(model)\n",
    "\n",
    "if MODE == 'encoder':\n",
    "    DISTILLER = EncDistiller\n",
    "    params = student.model.image_encoder.parameters()\n",
    "else:\n",
    "    DISTILLER = DecDistiller\n",
    "    params = student.model.mask_decoder.parameters()\n",
    "\n",
    "if OPTIM == 'adamw':\n",
    "    optimizer = torch.optim.AdamW(params, lr=LR, weight_decay=WD)\n",
    "elif OPTIM == 'adam':\n",
    "    optimizer = torch.optim.Adam(params, lr=LR)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "\n",
    "distiller = DISTILLER(teacher, student, processor, dataloader, optimizer, scheduler, loss_weights=LOSS_WEIGHTS, device=DEVICE)\n",
    "\n",
    "if MODE == 'save_features':\n",
    "    distiller.save_teacher_features(Path('results/teacher_features.pt'))\n",
    "else:\n",
    "    distiller.distill(epochs=EPOCHS, accumulate=BATCH_SIZE, use_saved_features=LOAD_FEATURES, name=MODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pstats import Stats\n",
    "\n",
    "filename = '../results/profile.prof' \n",
    "my_stat = Stats(filename, stream=sys.stdout).sort_stats('time')\n",
    "my_stat.print_stats(.1)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distiller Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from transformers import (SamModel, SamProcessor)\n",
    "from utils.mobile_sam import sam_model_registry\n",
    "from utils.mobile_sam.predictor import SamPredictor\n",
    "from utils.datasets import SA1B_Dataset\n",
    "from utils.utils import *\n",
    "from utils.distill_utils import *\n",
    "\n",
    "from ipywidgets import Button\n",
    "import asyncio\n",
    "from IPython.display import clear_output\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_for_change(widget):\n",
    "    future = asyncio.Future()\n",
    "    def getvalue(change):\n",
    "        future.set_result(change.description)\n",
    "        widget.on_click(getvalue, remove=True) \n",
    "        # we need to free up the binding to getvalue to avoid an InvalidState error\n",
    "        # buttons don't support unobserve\n",
    "        # so use `remove=True` \n",
    "    widget.on_click(getvalue)\n",
    "    return future\n",
    "\n",
    "class InspectDistiller(DecDistiller):\n",
    "    def __init__(self, teacher, student, processor, dataloader, test_dataloader, optimizer, scheduler, loss_weights=[0,0,0,0,1,0], \n",
    "                 n_prompts=1, random_prompt=True, edge_filter=True, size_thr=0, profile=False, device='cuda', button=None):\n",
    "        super().__init__(teacher, student, processor, dataloader, test_dataloader, optimizer, scheduler, loss_weights, \n",
    "                         n_prompts, random_prompt, edge_filter, size_thr, profile, device)\n",
    "        self.BUTTON = button\n",
    "        \n",
    "    '''\n",
    "    def get_loss(self, t_mask, s_mask, label):\n",
    "        t_mask_bin = (t_mask > 0.0)\n",
    "        focal = self.focal_loss(s_mask, t_mask_bin.float())\n",
    "        bce = self.bce_loss(s_mask, t_mask_bin.float())\n",
    "        iou = self.iou_loss(s_mask, t_mask_bin.int())\n",
    "        dice = self.dice_loss(s_mask, t_mask_bin.int())\n",
    "        #bce_gt = self.bce_loss(s_mask, label.float())\n",
    "        #iou_gt = self.iou_loss(s_mask, label.int())\n",
    "        #bound = self.bound_loss(s_mask, label.int())\n",
    "        return focal, bce, iou, dice\n",
    "\n",
    "    def get_prompt(self, label, seed=None):\n",
    "        C, counts = np.unique(label.cpu(), return_counts=True)\n",
    "        counts = counts / counts.sum()\n",
    "        C = C[counts > 0.001]\n",
    "        # print(C)\n",
    "        if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "        c = np.random.choice(C)\n",
    "\n",
    "        x_v, y_v = np.where(label.cpu() == c)\n",
    "        if self.random_prompt:\n",
    "            if seed is not None:\n",
    "                random.seed(seed)\n",
    "            r = random.randint(0, len(x_v) - 1)\n",
    "            x, y = x_v[r], y_v[r]\n",
    "        else: # central prompt\n",
    "            x, y = x_v.mean(), y_v.mean()\n",
    "            x, y = int(x), int(y)\n",
    "        return [[[y,x]]], c # inverted to compensate different indexing\n",
    "    '''\n",
    "\n",
    "    def training_step(self, i, img, label, feats, acc, use_saved_features=False):\n",
    "        feats = feats.to(self.device) if use_saved_features else None\n",
    "        self.get_features(img)\n",
    "        prompts = self.get_prompts(label[0], seed=8)\n",
    "        label = label.to(self.device)\n",
    "        # print(prompts)\n",
    "\n",
    "        for prompt, c in prompts:\n",
    "            # show_points_on_image(img[0], prompt[0], np.array([1]), title='Prompt') \n",
    "            # show_points_on_image((label[0]==c).cpu().numpy(), prompt[0], np.array([1]), \n",
    "            #                      title=f'GT size:{(label[0]==c).cpu().numpy().sum()}')\n",
    "            t_mask, s_mask = self.get_masks(img, prompt, feats)\n",
    "            focal, bce, iou, dice = self.get_loss(t_mask, s_mask, label[0]==c)\n",
    "            loss = (self.FW * focal + self.BW * bce + self.IW * iou) / acc\n",
    "            loss.backward(retain_graph=True)\n",
    "            # print(f\"GT  BCE: {bce_gt.item():.2e} IoU: {iou_gt.item():.2e}\")\n",
    "            show_points_on_image(t_mask.cpu().numpy(), prompt[0], np.array([1]), title='Teacher Raw')\n",
    "            show_points_on_image(s_mask.detach().cpu().numpy(), prompt[0], np.array([1]), title='Student Raw') \n",
    "            show_points_on_image((t_mask>0).cpu().numpy(), prompt[0], np.array([1]), title='Teacher Mask') \n",
    "            show_points_on_image((s_mask>0).detach().cpu().numpy(), prompt[0], np.array([1]), title='Student Mask') \n",
    "            print(f\"BCE: {bce.item():.2e} IoU: {iou.item():.2e} Focal: {focal.item():.2e} Dice: {dice.item():.2e}\")\n",
    "            self.update_metrics(loss, focal, bce, iou, dice)\n",
    "\n",
    "        if (i+1) % acc == 0 or i+1 == len(self.dataloader):\n",
    "            print(f\"BCE: {self.r_bce/(i+1):.2e} IoU: {self.r_iou/(i+1):.2e} Focal: {self.r_focal/(i+1):.2e} Dice: {self.r_dice/(i+1):.2e}\")\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "    async def distill(self, epochs=8, acc=4, use_saved_features=False, name=''):\n",
    "        self.acc = acc\n",
    "        self.student.model.mask_decoder.train()\n",
    "        self.student.model.prompt_encoder.train()\n",
    "        self.student.model.image_encoder.eval()\n",
    "\n",
    "        self.init_metrics()\n",
    "        for i, (img, label, _, feats) in enumerate(self.dataloader):\n",
    "            self.training_step(i, img, label, feats, acc, use_saved_features)\n",
    "            print('Waiting for button click...')\n",
    "            _ = await wait_for_change(self.BUTTON)\n",
    "            clear_output(wait=True)\n",
    "            print('Button clicked!')\n",
    "            break\n",
    "\n",
    "        self.validate(use_saved_features=use_saved_features)\n",
    "\n",
    "    def validate(self, use_saved_features=False):\n",
    "        self.student.model.mask_decoder.eval()\n",
    "        self.student.model.prompt_encoder.eval()\n",
    "        self.student.model.image_encoder.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "            r_iou = 0\n",
    "            for img, label, _, feats in self.test_dataloader:\n",
    "                feats = feats.to(self.device) if use_saved_features else None\n",
    "                self.get_features(img)\n",
    "                prompt, c = self.get_prompt(label[0], seed=0)\n",
    "                label = label.to(self.device)\n",
    "\n",
    "                t_mask, s_mask = self.get_masks(img, prompt, feats)\n",
    "                \n",
    "                show_points_on_image(t_mask.cpu().numpy(), prompt[0], np.array([1]), title='Teacher Raw')\n",
    "                show_points_on_image(s_mask.detach().cpu().numpy(), prompt[0], np.array([1]), title='Student Raw') \n",
    "                show_points_on_image((t_mask>0).cpu().numpy(), prompt[0], np.array([1]), title='Teacher Mask') \n",
    "                show_points_on_image((s_mask>0).detach().cpu().numpy(), prompt[0], np.array([1]), title='Student Mask') \n",
    "\n",
    "                focal, bce, iou, dice = self.get_loss(t_mask, s_mask, label[0]==c)\n",
    "                loss = self.FW * focal + self.BW * bce + self.IW * iou + self.DW * dice\n",
    "\n",
    "                iou = self.get_metrics(t_mask, s_mask, label[0]==c)\n",
    "                r_iou += iou\n",
    "                print(f\"Loss: {loss.item():.2e} BCE: {bce.item():.2e} IoU: {iou:.2e} Focal: {focal.item():.2e} Dice: {dice.item():.2e}\")\n",
    "                #print('Waiting for button click...')\n",
    "                #_ = await wait_for_change(self.BUTTON)\n",
    "                #clear_output(wait=True)\n",
    "                #print('Button clicked!')\n",
    "\n",
    "            return r_iou / len(self.test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config.yaml', 'r') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "cfg['DATA_DIR'] = Path('../' + cfg['DATA_DIR'])\n",
    "cfg['DEVICE'] = torch.device(f\"cuda:{cfg['GPU']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "cfg['PRETRAINED'] = True if cfg['MODE'] == 'decoder' else False\n",
    "DISTILLER = InspectDistiller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SA1B_Dataset(root=cfg['DATA_DIR'].joinpath('SA_1B/images/'), split=[\"sa_00000\" + str(i) for i in range(cfg['TRAIN_SPLITS'])],\n",
    "                        features=None, labels=True)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=cfg['SHUFFLE'], num_workers=cfg['NUM_WORKERS'], pin_memory=False)\n",
    "test_dataset = SA1B_Dataset(root=cfg['DATA_DIR'].joinpath('SA_1B/images/'), split=[cfg['SPLIT']], \n",
    "                            features=None, labels=True, max=cfg['MAX_TEST'])\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=cfg['NUM_WORKERS'], pin_memory=False)\n",
    "\n",
    "teacher = SamModel.from_pretrained(\"facebook/sam-vit-huge\").to(cfg['DEVICE'])\n",
    "teacher.eval()\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")\n",
    "\n",
    "sam_checkpoint = \"../bin/mobile_sam.pt\" if cfg['PRETRAINED'] else None\n",
    "model = sam_model_registry[\"vit_t\"](checkpoint=sam_checkpoint, size_embedding=cfg['SIZE_EMBEDDING']).to(cfg['DEVICE'])\n",
    "model.eval()\n",
    "for m in model.image_encoder.modules():\n",
    "    if isinstance(m, torch.nn.BatchNorm2d):\n",
    "        m.eval()\n",
    "        m.weight.requires_grad_(False)\n",
    "        m.bias.requires_grad_(False)\n",
    "student = SamPredictor(model)\n",
    "\n",
    "params = list(student.model.mask_decoder.parameters()) + list(student.model.prompt_encoder.parameters())\n",
    "\n",
    "if cfg['OPTIM'] == 'adamw':\n",
    "    optimizer = torch.optim.AdamW(params, lr=cfg['LR'], weight_decay=cfg['WD'])\n",
    "if cfg['SCHEDULER'] == 'cos':\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=cfg['EPOCHS'], eta_min=1.0e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distiller = DISTILLER(teacher, student, processor, dataloader, test_dataloader, optimizer, scheduler, loss_weights=cfg['LOSS_WEIGHTS'], \n",
    "                      n_prompts=cfg['N_PROMPTS'], random_prompt=cfg['RANDOM_PROMPT'], edge_filter=cfg['EDGE_FILTER'], size_thr=cfg['SIZE_THR'],\n",
    "                      profile=cfg['PROFILE'], device=cfg['DEVICE'], button=Button(description='step()'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asyncio.create_task(distiller.distill(epochs=cfg['EPOCHS'], acc=cfg['BATCH_SIZE'],\n",
    "use_saved_features=cfg['LOAD_FEATURES'], name=f\"{cfg['MODE']}_{cfg['EXP']}\"))\n",
    "#asyncio.create_task(distiller.validate(use_saved_features=cfg['LOAD_FEATURES']))\n",
    "distiller.BUTTON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distiller.BUTTON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAM in MobileSAM Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 7\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from utils.mobile_sam import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n",
    "from transformers import pipeline, SamModel, SamProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.4])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30 / 255, 144 / 255, 255 / 255, 0.4])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    del mask\n",
    "\n",
    "def show_masks_on_image(raw_image, masks):\n",
    "  plt.imshow(np.array(raw_image))\n",
    "  ax = plt.gca()\n",
    "  ax.set_autoscale_on(False)\n",
    "  for mask in masks:\n",
    "      show_mask(mask, ax=ax, random_color=False)\n",
    "  plt.axis(\"off\")\n",
    "  plt.show()\n",
    "  del mask\n",
    "\n",
    "def show_anns(anns):\n",
    "    if len(anns) == 0:\n",
    "        return\n",
    "    sorted_anns = sorted(anns, key=(lambda x: x['area']), reverse=True)\n",
    "    ax = plt.gca()\n",
    "    ax.set_autoscale_on(False)\n",
    "\n",
    "    img = np.ones((sorted_anns[0]['segmentation'].shape[0], sorted_anns[0]['segmentation'].shape[1], 4))\n",
    "    img[:,:,3] = 0\n",
    "    for ann in sorted_anns:\n",
    "        m = ann['segmentation']\n",
    "        color_mask = np.concatenate([np.random.random(3), [0.35]])\n",
    "        img[m] = color_mask\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original SAM\n",
    "SAM = SamModel.from_pretrained(\"facebook/sam-vit-huge\").to(DEVICE)\n",
    "SAM.eval()\n",
    "SAM_processor = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")\n",
    "SAM_gen = pipeline(\"mask-generation\", model=\"facebook/sam-vit-huge\", device=0)\n",
    "\n",
    "# MobileSAM's SAM\n",
    "model_type = \"vit_h\"\n",
    "sam_checkpoint = \"../bin/sam_vit_h_4b8939.pth\"\n",
    "TEST = sam_model_registry[model_type](checkpoint=sam_checkpoint).to(DEVICE)\n",
    "TEST.eval()\n",
    "TEST_processor = SamPredictor(TEST)\n",
    "TEST_gen = SamAutomaticMaskGenerator(TEST)\n",
    "\n",
    "# MobileSAM's MobileSAM\n",
    "model_type = \"vit_t\"\n",
    "sam_checkpoint = \"../bin/mobile_sam.pt\"\n",
    "MOBILESAM = sam_model_registry[model_type](checkpoint=sam_checkpoint).to(DEVICE)\n",
    "MOBILESAM.eval()\n",
    "MOBILESAM_processor = SamPredictor(MOBILESAM)\n",
    "MOBILESAM_gen = SamAutomaticMaskGenerator(MOBILESAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "img_url = \"https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg\"\n",
    "raw_image = Image.open(requests.get(img_url, stream=True).raw).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = SAM_gen(raw_image, points_per_batch=64)\n",
    "masks = outputs[\"masks\"]\n",
    "show_masks_on_image(raw_image, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_masks = TEST_gen.generate(np.array(raw_image))\n",
    "sam_masks = [m['segmentation'] for m in sam_masks]\n",
    "show_masks_on_image(raw_image, sam_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobilesam_masks = MOBILESAM_gen.generate(np.array(raw_image))\n",
    "mobilesam_masks = [m['segmentation'] for m in mobilesam_masks]\n",
    "show_masks_on_image(raw_image, mobilesam_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = []\n",
    "for s, m in zip(sam_masks, mobilesam_masks):\n",
    "    s = s.astype(float)\n",
    "    m = m.astype(float)\n",
    "    e = np.mean((s-m)**2)\n",
    "    mae.append(e)\n",
    "    if e > 1e-4:\n",
    "        plt.imshow(s, alpha=0.6)\n",
    "        plt.imshow(m, alpha=0.6)\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "np.mean(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Size Prompt Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "EMBED_DIM = 256\n",
    "CLASSES = 10\n",
    "DEVICE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delimiters = [5e-4, 8e-4, 1e-3, 2e-3, 3e-3, 5e-3, 9e-3, 2e-2, 9e-2]\n",
    "size_label = list(range(CLASSES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def size_to_label(size):\n",
    "    # return the label of the size based on the delimiters\n",
    "    for l, d in zip(CLASSES, delimiters):\n",
    "        if size < d:\n",
    "            return l\n",
    "    return size_label[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_embedding = torch.nn.Embedding(len(size_label), EMBED_DIM).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 3e-3\n",
    "size_class = torch.tensor(size_to_label(size)).to(DEVICE)\n",
    "emb = size_embedding(size_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_embedding.weight.grad_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainable Prompt Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torch\n",
    "from utils.mobile_sam import sam_model_registry\n",
    "from utils.mobile_sam.predictor import SamPredictor\n",
    "from utils.utils import *\n",
    "from utils.distill_utils import *\n",
    "from utils.datasets import SA1B_Dataset\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_checkpoint = \"../bin/mobile_sam.pt\"\n",
    "model = sam_model_registry[\"vit_t\"](checkpoint=sam_checkpoint, add_prompt='zero').to('cuda')\n",
    "model.eval()\n",
    "for m in model.image_encoder.modules():\n",
    "    if isinstance(m, torch.nn.BatchNorm2d):\n",
    "        m.eval()\n",
    "        m.weight.requires_grad_(False)\n",
    "        m.bias.requires_grad_(False)\n",
    "student = SamPredictor(model)\n",
    "\n",
    "params = list(student.model.mask_decoder.parameters()) + list(student.model.prompt_encoder.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student.model.prompt_encoder.point_embeddings[4].train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student.model.state_dict(), '../bin/mobile_sam_zero.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(student.model.prompt_encoder.point_embeddings[4].parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.load('../bin/mobile_sam_zero.pt')\n",
    "f = torch.load('../bin/distilled_mobile_sam_prompt_.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, w in enumerate(m.keys()):\n",
    "    if not (m[w].cpu() == f[w].cpu()).all().item():\n",
    "        print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f['prompt_encoder.point_embeddings.4.weight'], m['prompt_encoder.point_embeddings.4.weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SA1B_Dataset(root='../../Datasets/SA_1B/images/', split=[\"sa_00000\" + str(i) for i in range(1)],\n",
    "                       features=None, labels=True)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=8, pin_memory=False)\n",
    "\n",
    "STL = 1e-4\n",
    "STH = 5e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(label, image):\n",
    "    C, counts = np.unique(label.cpu(), return_counts=True)\n",
    "    counts = (counts / counts.sum())[1:]\n",
    "    Cf = C[1:][(counts > STL) * (counts < STH)]\n",
    "    if len(Cf) == 0:\n",
    "        print('No prompts found!')\n",
    "        plt.imshow(image.cpu().numpy())\n",
    "        plt.imshow(label.cpu().numpy(), alpha=0.5)\n",
    "        plt.show()\n",
    "        Cf = C[1:][counts > STL]\n",
    "    c = np.random.choice(Cf)\n",
    "    x_v, y_v = np.where(label.cpu() == c)\n",
    "    x, y = x_v.mean(), y_v.mean()\n",
    "    x, y = int(x), int(y)\n",
    "    return [[[y,x]]], c\n",
    "\n",
    "def get_prompts(label, image):\n",
    "    h, w = label.shape\n",
    "    margin_h, margin_w = h // 1, w // 1\n",
    "    prompts = []\n",
    "    for point_h in range(1):\n",
    "        for point_w in range(1):\n",
    "            crop = label[point_h*margin_h : (point_h+1)*margin_h, point_w*margin_w : (point_w+1)*margin_w]\n",
    "            local_prompt, c = get_prompt(crop, image)\n",
    "            prompt = [[local_prompt[0][0][0] + point_w * margin_w, local_prompt[0][0][1] + point_h * margin_h]]\n",
    "            prompts.append(([prompt], c))\n",
    "    return prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (img, label, _, feats) in enumerate(dataloader):\n",
    "    prompt, c = get_prompt(label[0], img[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(paths, imsize=(10, 3), scatter=False, sam=True):\n",
    "    f = plt.scatter if scatter else plt.plot\n",
    "    for path in paths:\n",
    "        summ = json.load(open(path, 'r'))\n",
    "        x = range(len(summ['TRAIN']['LOSS']))\n",
    "        plt.figure(figsize=imsize)\n",
    "        f(x, 1 - np.array(summ['TRAIN']['LOSS']), label='Train gtIoU')\n",
    "        f(x, summ['VAL']['GT_IOU'], label='Val gtIoU')\n",
    "        if sam:\n",
    "            f(x, 1 - np.array(summ['TRAIN']['IOU']), label='Train samIoU')\n",
    "            f(x, summ['VAL']['IOU'], label='Val samIoU')\n",
    "        plt.legend()\n",
    "        last = summ['GT_IOU'] if summ['GT_IOU'] != 0 else summ['VAL']['GT_IOU'][-1]\n",
    "        plt.title(f\"{path.split('/')[-1].split('.')[0]}: {last:.4f}\")\n",
    "        plt.xlim(0, summ['EPOCHS'])\n",
    "        plt.grid()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = ['../bin/configs/prompt_new_prompt.json', '../bin/configs/prompt_data.json', '../bin/configs/prompt_large.json']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(paths, scatter=False, sam=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Attention Maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import torch\n",
    "from transformers import SamModel, SamProcessor\n",
    "from utils.mobile_sam import sam_model_registry\n",
    "from utils.mobile_sam.predictor import SamPredictor\n",
    "from utils.datasets import SA1B_Dataset\n",
    "from utils.utils import *\n",
    "from utils.distill_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config_distillation.yaml', 'r') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "cfg['DATA_DIR'] = Path('../').joinpath(cfg['DATA_DIR'])\n",
    "cfg['OUTPUT_DIR'] = Path('../').joinpath(cfg['OUTPUT_DIR'])\n",
    "cfg['MODEL_DIR'] = Path('../').joinpath(cfg['MODEL_DIR'])\n",
    "cfg['PROMPT_DIR'] = cfg['OUTPUT_DIR'].joinpath(f\"prompts.pkl\")\n",
    "cfg['DEVICE'] = torch.device(f\"cuda:{cfg['GPU']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "cfg['PRETRAINED'] = True if cfg['MODE'] in ['decoder', 'prompt'] else False\n",
    "\n",
    "# DATASET\n",
    "dataset = SA1B_Dataset(root=cfg['DATA_DIR'], split=[\"sa_00000\" + str(i) for i in range(cfg['TRAIN_SPLITS'])],\n",
    "                        features=None, labels=True)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=cfg['SHUFFLE'], num_workers=cfg['WORKERS'], pin_memory=False)\n",
    "test_dataset = SA1B_Dataset(root=cfg['DATA_DIR'], split=[cfg['SPLIT']], \n",
    "                            features=None, labels=True, max_samples=cfg['MAX_TEST'])\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=cfg['WORKERS'], pin_memory=False)\n",
    "\n",
    "# MODEL\n",
    "teacher = SamModel.from_pretrained(\"facebook/sam-vit-huge\").to(cfg['DEVICE'])\n",
    "teacher.eval()\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")\n",
    "sam_checkpoint = cfg['MODEL_DIR'].joinpath(cfg['CKPT']) if cfg['PRETRAINED'] else None\n",
    "model = sam_model_registry[\"vit_t\"](checkpoint=sam_checkpoint, add_prompt=cfg['ADD_PROMPT']) #.to(cfg['DEVICE'])\n",
    "model.eval()\n",
    "for m in model.image_encoder.modules():\n",
    "    if isinstance(m, torch.nn.BatchNorm2d):\n",
    "        m.eval()\n",
    "        m.weight.requires_grad_(False)\n",
    "        m.bias.requires_grad_(False)\n",
    "student = SamPredictor(model, return_attn=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTILLER = DecDistiller\n",
    "module = student.model.prompt_encoder.point_embeddings\n",
    "params = module[4].parameters() if not cfg['TEST'] else module.parameters()\n",
    "\n",
    "optimizer = torch.optim.AdamW(params, lr=cfg['LR'], weight_decay=cfg['WD'])\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=1.0)\n",
    "\n",
    "distiller = DISTILLER(teacher, student, processor, dataloader, test_dataloader, optimizer, scheduler, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(self, use_saved_features=False, save=False, save_sam=False):\n",
    "    self.set_trainable_weights(train=False)\n",
    "    with torch.no_grad():\n",
    "        t = qqdm(self.test_dataloader, desc=format_str('bold', 'Validation'))\n",
    "        for img, label, name, feats in t:\n",
    "            feats = feats.to(self.device) if use_saved_features else None\n",
    "            self.get_features(img)\n",
    "            prompt, c = self.get_prompt(label[0], name=name[0], seed=self.cfg['SEED'])\n",
    "            if prompt is None:\n",
    "                continue\n",
    "            label = label.to(self.device)\n",
    "            s_mask, attn = self.get_masks(img, prompt, feats)\n",
    "            break\n",
    "        return label[0]==c, s_mask, attn\n",
    "    \n",
    "def get_masks(self, img, prompt, t_features):\n",
    "    masks, scores, _, attn = self.student.predict(np.array(prompt[0]), np.array([1]), return_logits=True)\n",
    "    s_mask = masks.squeeze()[scores.argmax()]\n",
    "    return s_mask, attn\n",
    "\n",
    "distiller.validate = validate.__get__(distiller, DISTILLER)\n",
    "distiller.get_masks = get_masks.__get__(distiller, DISTILLER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " \u001b[1mIters\u001b[0m     \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m                                              \n",
      " \u001b[99m0/\u001b[93m2500\u001b[0m\u001b[0m  \u001b[99m        -        \u001b[0m  \u001b[99m   -    \u001b[0m                                            \n",
      "\u001b[1mValidation\u001b[0m   0.0% |                                                            |"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[K\u001b[F\u001b[K\u001b[F \u001b[1mIters\u001b[0m     \u001b[1mElapsed Time\u001b[0m      \u001b[1mSpeed\u001b[0m                                              \n",
      " \u001b[99m0/\u001b[93m2500\u001b[0m\u001b[0m  \u001b[99m        -        \u001b[0m  \u001b[99m   -    \u001b[0m                                            \n",
      "\u001b[1mValidation\u001b[0m   0.0% |                                                            |"
     ]
    }
   ],
   "source": [
    "label, mask, attns = distiller.validate(use_saved_features=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f51774286a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAF7CAYAAADMhrFdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA0aUlEQVR4nO3de3RU5b3/8c9MkpmEy0wIMTOMBsTLQVBEAYnxQrWkBKRWKz2K5ii2HGhtYmtBRE4rXnoBsccLloJ2VXEtsVrXErQci0YQ4yUGCEbkloKlEIRJ0JAZAiSZZJ7fH/yYOhIuCRNmdvJ+rTVrkf18957v4zbDhz37YjPGGAEAAFiIPd4NAAAAtBUBBgAAWA4BBgAAWA4BBgAAWA4BBgAAWA4BBgAAWA4BBgAAWA4BBgAAWA4BBgAAWA4BBgAAWE5CB5j58+fr7LPPVmpqqnJycrR69ep4twQAABJAwgaYV155RVOnTtWDDz6odevWaciQIcrPz1dNTU28WwMAAHFmS9SHOebk5Oiyyy7TH/7wB0lSOBxWdna27r77bt1///1x7g4AAMRTcrwbaE1TU5PKy8s1c+bMyDK73a68vDyVlpa2uk5jY6MaGxsjP4fDYdXW1qp3796y2Wwd3jMAADh1xhjt379fPp9PdvuxvyhKyADz5ZdfqqWlRR6PJ2q5x+PRli1bWl1n9uzZevjhh09HewAAoINVVVXprLPOOuZ4QgaY9pg5c6amTp0a+TkQCKhv3766StcpWSlx7AwAAJysZoX0gd5Uz549j1uXkAEmMzNTSUlJqq6ujlpeXV0tr9fb6jpOp1NOp/Oo5clKUbKNAAMAgCX8/zNzT3T6R0JeheRwODRs2DCtWLEisiwcDmvFihXKzc2NY2cAACARJOQRGEmaOnWqJk6cqOHDh2vEiBF68skndeDAAf3whz+Md2sAACDOEjbA3HLLLdq7d69mzZolv9+vSy65RMuXLz/qxF4AAND1JOx9YE5VMBiU2+3WNbqBc2AAALCIZhPSKr2uQCAgl8t1zLqEPAcGAADgeAgwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcggwAADAcmIeYGbPnq3LLrtMPXv2VFZWlm688UZVVlZG1TQ0NKiwsFC9e/dWjx49NH78eFVXV0fV7Ny5U+PGjVO3bt2UlZWl6dOnq7m5OdbtAgAAC4p5gHnvvfdUWFiojz/+WMXFxQqFQho9erQOHDgQqfnFL36hv/3tb3r11Vf13nvvaffu3brpppsi4y0tLRo3bpyampr00Ucf6YUXXtCiRYs0a9asWLcLAAAsyGaMMR35Bnv37lVWVpbee+89jRw5UoFAQGeccYZeeukl/eAHP5AkbdmyRQMHDlRpaakuv/xy/f3vf9d3v/td7d69Wx6PR5K0cOFCzZgxQ3v37pXD4Tjh+waDQbndbl2jG5RsS+nIKQIAgBhpNiGt0usKBAJyuVzHrOvwc2ACgYAkKSMjQ5JUXl6uUCikvLy8SM0FF1ygvn37qrS0VJJUWlqqwYMHR8KLJOXn5ysYDGrjxo2tvk9jY6OCwWDUCwAAdE4dGmDC4bDuueceXXnllbroooskSX6/Xw6HQ+np6VG1Ho9Hfr8/UvP18HJk/MhYa2bPni232x15ZWdnx3g2AAAgUXRogCksLNSGDRv08ssvd+TbSJJmzpypQCAQeVVVVXX4ewIAgPhI7qgNFxUVadmyZSopKdFZZ50VWe71etXU1KS6urqoozDV1dXyer2RmtWrV0dt78hVSkdqvsnpdMrpdMZ4FgAAIBHF/AiMMUZFRUVasmSJVq5cqf79+0eNDxs2TCkpKVqxYkVkWWVlpXbu3Knc3FxJUm5urj777DPV1NREaoqLi+VyuTRo0KBYtwwAACwm5kdgCgsL9dJLL+n1119Xz549I+esuN1upaWlye12a9KkSZo6daoyMjLkcrl09913Kzc3V5dffrkkafTo0Ro0aJBuv/12zZ07V36/X7/61a9UWFjIURYAABD7y6htNlury59//nndeeedkg7fyG7atGn6y1/+osbGRuXn5+uPf/xj1NdDO3bs0F133aVVq1ape/fumjhxoubMmaPk5JPLXFxGDQCA9ZzsZdQdfh+YeCHAAABgPQlzHxgAAIBYI8AAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADLIcAAAADL6fAAM2fOHNlsNt1zzz2RZQ0NDSosLFTv3r3Vo0cPjR8/XtXV1VHr7dy5U+PGjVO3bt2UlZWl6dOnq7m5uaPbBQAAFtChAWbNmjV65plndPHFF0ct/8UvfqG//e1vevXVV/Xee+9p9+7duummmyLjLS0tGjdunJqamvTRRx/phRde0KJFizRr1qyObBcAAFhEhwWY+vp6FRQU6E9/+pN69eoVWR4IBPTnP/9Zjz/+uL797W9r2LBhev755/XRRx/p448/liS9/fbb2rRpk1588UVdcsklGjt2rH79619r/vz5ampq6qiWAQCARXRYgCksLNS4ceOUl5cXtby8vFyhUChq+QUXXKC+ffuqtLRUklRaWqrBgwfL4/FEavLz8xUMBrVx48ZW36+xsVHBYDDqBQAAOqfkjtjoyy+/rHXr1mnNmjVHjfn9fjkcDqWnp0ct93g88vv9kZqvh5cj40fGWjN79mw9/PDDMegeAAAkupgfgamqqtLPf/5zLV68WKmpqbHe/DHNnDlTgUAg8qqqqjpt7w0AAE6vmAeY8vJy1dTUaOjQoUpOTlZycrLee+89zZs3T8nJyfJ4PGpqalJdXV3UetXV1fJ6vZIkr9d71FVJR34+UvNNTqdTLpcr6gUAADqnmAeYUaNG6bPPPlNFRUXkNXz4cBUUFET+nJKSohUrVkTWqays1M6dO5WbmytJys3N1WeffaaamppITXFxsVwulwYNGhTrlgEAgMXE/ByYnj176qKLLopa1r17d/Xu3TuyfNKkSZo6daoyMjLkcrl09913Kzc3V5dffrkkafTo0Ro0aJBuv/12zZ07V36/X7/61a9UWFgop9MZ65YBAIDFdMhJvCfyxBNPyG63a/z48WpsbFR+fr7++Mc/RsaTkpK0bNky3XXXXcrNzVX37t01ceJEPfLII/FoFwAAJBibMcbEu4mOEAwG5Xa7dY1uULItJd7tAACAk9BsQlql1xUIBI57PivPQgIAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJZDgAEAAJbTIQHmiy++0H/913+pd+/eSktL0+DBg7V27drIuDFGs2bNUp8+fZSWlqa8vDxt3bo1ahu1tbUqKCiQy+VSenq6Jk2apPr6+o5oFwAAWEzMA8y+fft05ZVXKiUlRX//+9+1adMm/e///q969eoVqZk7d67mzZunhQsXqqysTN27d1d+fr4aGhoiNQUFBdq4caOKi4u1bNkylZSUaMqUKbFuFwAAWJDNGGNiucH7779fH374od5///1Wx40x8vl8mjZtmu69915JUiAQkMfj0aJFizRhwgRt3rxZgwYN0po1azR8+HBJ0vLly3Xddddp165d8vl8J+wjGAzK7XbrGt2gZFtK7CYIAAA6TLMJaZVeVyAQkMvlOmZdzI/AvPHGGxo+fLj+8z//U1lZWbr00kv1pz/9KTK+fft2+f1+5eXlRZa53W7l5OSotLRUklRaWqr09PRIeJGkvLw82e12lZWVtfq+jY2NCgaDUS8AANA5xTzA/POf/9SCBQt0/vnn66233tJdd92ln/3sZ3rhhRckSX6/X5Lk8Xii1vN4PJExv9+vrKysqPHk5GRlZGREar5p9uzZcrvdkVd2dnaspwYAABJEzANMOBzW0KFD9bvf/U6XXnqppkyZosmTJ2vhwoWxfqsoM2fOVCAQiLyqqqo69P0AAED8xDzA9OnTR4MGDYpaNnDgQO3cuVOS5PV6JUnV1dVRNdXV1ZExr9ermpqaqPHm5mbV1tZGar7J6XTK5XJFvQAAQOcU8wBz5ZVXqrKyMmrZP/7xD/Xr10+S1L9/f3m9Xq1YsSIyHgwGVVZWptzcXElSbm6u6urqVF5eHqlZuXKlwuGwcnJyYt0yAACwmORYb/AXv/iFrrjiCv3ud7/TzTffrNWrV+vZZ5/Vs88+K0my2Wy655579Jvf/Ebnn3+++vfvrwceeEA+n0833nijpMNHbMaMGRP56ikUCqmoqEgTJkw4qSuQAABA5xbzAHPZZZdpyZIlmjlzph555BH1799fTz75pAoKCiI19913nw4cOKApU6aorq5OV111lZYvX67U1NRIzeLFi1VUVKRRo0bJbrdr/PjxmjdvXqzbBQAAFhTz+8AkCu4DAwCA9cTtPjAAAAAdjQADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAshwADAAAsJ+YBpqWlRQ888ID69++vtLQ0nXvuufr1r38tY0ykxhijWbNmqU+fPkpLS1NeXp62bt0atZ3a2loVFBTI5XIpPT1dkyZNUn19fazbBQAAFhTzAPPoo49qwYIF+sMf/qDNmzfr0Ucf1dy5c/X0009HaubOnat58+Zp4cKFKisrU/fu3ZWfn6+GhoZITUFBgTZu3Kji4mItW7ZMJSUlmjJlSqzbBQAAFmQzXz80EgPf/e535fF49Oc//zmybPz48UpLS9OLL74oY4x8Pp+mTZume++9V5IUCATk8Xi0aNEiTZgwQZs3b9agQYO0Zs0aDR8+XJK0fPlyXXfdddq1a5d8Pt8J+wgGg3K73bpGNyjZlhLLKQIAgA7SbEJapdcVCATkcrmOWRfzIzBXXHGFVqxYoX/84x+SpE8//VQffPCBxo4dK0navn27/H6/8vLyIuu43W7l5OSotLRUklRaWqr09PRIeJGkvLw82e12lZWVtfq+jY2NCgaDUS8AANA5Jcd6g/fff7+CwaAuuOACJSUlqaWlRb/97W9VUFAgSfL7/ZIkj8cTtZ7H44mM+f1+ZWVlRTeanKyMjIxIzTfNnj1bDz/8cKynAwAAElDMj8D89a9/1eLFi/XSSy9p3bp1euGFF/T73/9eL7zwQqzfKsrMmTMVCAQir6qqqg59PwAAED8xPwIzffp03X///ZowYYIkafDgwdqxY4dmz56tiRMnyuv1SpKqq6vVp0+fyHrV1dW65JJLJEler1c1NTVR221ublZtbW1k/W9yOp1yOp2xng4AAEhAMT8Cc/DgQdnt0ZtNSkpSOByWJPXv319er1crVqyIjAeDQZWVlSk3N1eSlJubq7q6OpWXl0dqVq5cqXA4rJycnFi3DAAALCbmR2Cuv/56/fa3v1Xfvn114YUX6pNPPtHjjz+uH/3oR5Ikm82me+65R7/5zW90/vnnq3///nrggQfk8/l04403SpIGDhyoMWPGaPLkyVq4cKFCoZCKioo0YcKEk7oCCQAAdG4xDzBPP/20HnjgAf30pz9VTU2NfD6ffvzjH2vWrFmRmvvuu08HDhzQlClTVFdXp6uuukrLly9XampqpGbx4sUqKirSqFGjZLfbNX78eM2bNy/W7QIAAAuK+X1gEgX3gQEAwHridh8YAACAjkaAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlkOAAQAAlhPzp1EDsAZbZobqLuiu5qyQMtYY2aqq490SAJw0AgzQBTUOOlODr92mnNQ6SdLqPm5teeMc2ar88W0MAE4SXyEBXUzDRWfputFlkfAiSSNSAxrx/Q1qPs8Xv8YAoA0IMEBXcpZHw6/ZJF9S0lFDF6SElHltjew9e8ahMQBoGwIM0EXYe/ZU9vVf6FLngWPWXO+qUs01PSWb7TR2BgBtR4ABuojQGT10RdqeE9bdeM462d2u09ARALQfAQboCux2HRicIacj7YSlZyaFFMrodhqaAoD2I8AAXUDDmKF69PEX5bg9RY0XnnXcr4jsNrtC3Y8+RwYAEgmXUQOdnc2mvT9s0Mg0m5S2XbXfqdSraVeo+9qqVsvDJixb+DT3CABtxBEYoJOzOZ26vv/6yM8ZSQ5dfvlG2dPdrdaXHvIq9fMvT1d7ANAuBBigs7Pb1dPeELVosOOg9n0nVfYePY4qX7e7r0xDw1HLASCREGCALshus+mu7E91RkG99l+ZLVtmhpT8/79RbuFjAUDi4xwYoLMzRl/UH/11kd1m03d6VOvbOXu0Z7j09leDlPq3ljg0CABtxz+1gE7OHGrQ+xsuOuZ4ks2us5LtujNrswIXtn5eDAAkGgIM0OkZnbHELn9z/XGr7Dab7H0PKSnNnKa+AKD9CDBAF+D8YJN+8s+bTlh3s/cTXZ+7Wzoz6zR0BQDtR4ABugBz6JD8z/TTh4dcajbR57kcCDfptbp+enHv+Xrjq8E6O0myf+eg7C4eJwAgcXESL9BF9PrbJr189gB9NtTo5ss/UkaSQ/tamvTKx1eox9o9UkujkiTJ1OnW3kbv3OrTrlVnKqXyi3i3DgBHIcAAXUS4/oDWvJ+t4aHVeiXpCnkvqNHedVnqUbFLMtHnvdhl0+gee1Q1ZrfeCQ9X8tbdceoaAFrHV0hAF9KrolZrD6Wr54dVOvhCi7p9UnVUePm67GSbLh/7mQ5dfPznJwHA6UaAAbqQcP0BrQ/4JEmmufmk1hmY0qT/HPWh6r5FiAGQONocYEpKSnT99dfL5/PJZrNp6dKlUePGGM2aNUt9+vRRWlqa8vLytHXr1qia2tpaFRQUyOVyKT09XZMmTVJ9ffQlnuvXr9fVV1+t1NRUZWdna+7cuW2fHYAotpQUDXL527xeL7tDt176oVrO9nZAVwDQdm0OMAcOHNCQIUM0f/78Vsfnzp2refPmaeHChSorK1P37t2Vn5+vhq89W6WgoEAbN25UcXGxli1bppKSEk2ZMiUyHgwGNXr0aPXr10/l5eV67LHH9NBDD+nZZ59txxQBRPTsof6Ove1aNdOeokOXh2LcEAC0j82Y43wBfqKVbTYtWbJEN954o6TDR198Pp+mTZume++9V5IUCATk8Xi0aNEiTZgwQZs3b9agQYO0Zs0aDR8+XJK0fPlyXXfdddq1a5d8Pp8WLFigX/7yl/L7/XI4HJKk+++/X0uXLtWWLVtOqrdgMCi3261rdIOSbSntnSLQqZhsj77/g9XqaXe0a/1toSSVLTpP4WAwxp0BwGHNJqRVel2BQECu49zOIabnwGzfvl1+v195eXmRZW63Wzk5OSotLZUklZaWKj09PRJeJCkvL092u11lZWWRmpEjR0bCiyTl5+ersrJS+/bta/W9GxsbFQwGo14AojX0TlF3e/sDfd/kRjV6e8awIwBon5gGGL//8HfrHo8narnH44mM+f1+ZWVF3+UzOTlZGRkZUTWtbePr7/FNs2fPltvtjryys7NPfUJAJ3Mo6/Al0u3lsCXroIdz/wHEX6f5JJo5c6YCgUDkVVVVFe+WgITj6N1w4qITcPY9EINOAODUxDTAeL2Hr1Corq6OWl5dXR0Z83q9qqmpiRpvbm5WbW1tVE1r2/j6e3yT0+mUy+WKegH4N5vDoUHpe055O8N67ZAtNTUGHQFA+8U0wPTv319er1crVqyILAsGgyorK1Nubq4kKTc3V3V1dSovL4/UrFy5UuFwWDk5OZGakpIShUL/vuKhuLhYAwYMUK9evWLZMtBl2BwpynbUnvJ2XPZDsqVwYjyA+GpzgKmvr1dFRYUqKiokHT5xt6KiQjt37pTNZtM999yj3/zmN3rjjTf02Wef6Y477pDP54tcqTRw4ECNGTNGkydP1urVq/Xhhx+qqKhIEyZMkM93+AZbt912mxwOhyZNmqSNGzfqlVde0VNPPaWpU6fGbOJAVxN2d1dv+6l/hdQnuUEt6d1i0BEAtF+bn4W0du1aXXvttZGfj4SKiRMnatGiRbrvvvt04MABTZkyRXV1dbrqqqu0fPlypX7tkPPixYtVVFSkUaNGyW63a/z48Zo3b15k3O126+2331ZhYaGGDRumzMxMzZo1K+peMQDaxtjtSorBnXQP/6uHO/ICiK9Tug9MIuM+MEA0e48eyp30uc5JDp/Sdg6ZkF59dYRsVW2/oy8AnEhc7gMDIHGZ5pCqm0/95PZGY2RrbolBRwDQfgQYoIswjU3a1ZBxytvZ09JDtkD9iQsBoAMRYAC0idPWLFtym0+fA4CYIsAAXYXNLoft1L/66ZPUqBY3VyEBiC8CDNBF2NJSNbDbF7HaWoy2AwDtQ4ABuopUp3raG+PdBQDEBAEG6CKaXU71tp/6XRMctmQ1ZHAODID4IsAAXUQ4xS5bDL76SZJNzal8hQQgvggwQBdx6Ay7UmxJp74dE1JaLfeBARBfBBigq4jRQZMtTelK+WJfbDYGAO1EgAG6iBZnbJ4asmH/mTIHD8VkWwDQXgQYoIuw926KyXYONfNsMQDxR4ABugpbbI7AuBwNUgyeag0Ap4IAA3QRjuTYnHg7qMce2ZzOmGwLANqLAAN0AbaUFA1y+2OyrWS1cAQGQNwRYICuoGd3neOoiXcXABAzBBigC2hOT1MvezjebQBAzBBggC6goVeS0mxcPQSg8yDAAF1Awxnx7gAAYosAA3QBtu7N8W4BAGKKAAN0cjaHQ5dmVcVse5sO+mQaY3NTPABoLwIM0NklJykzeX/MNrcn6JLCPMwRQHwRYIBOzhxq0MqaATHbXno3noMEIP4IMEBnZ4x6vdmgJz8fqpA59SMn++q7xaApADg1BBigCwjv36/M//tSC3cNPeVtmSCXYwOIPwIM0EWYUEjOSofCav9DHcMycu6LYVMA0E4EGKALSfsqpAPhULvXbzTNSt3HHX0BxB8BBuhCbE0tOpU7wpQc6KfkL76KWT8A0F4EGKAraWlRo2nfr31YRts+O0umoTHGTQFA2xFggK4ksF+fHOrXrlW/bGmRexuXUANIDAQYoAsxzc36vK53u9ZdfbC/VFsX24YAoJ0IMEAXY6pT27Xeth1emWaeqQQgMRBggC7G3o6LkFpk1H137HsBgPYiwABdTI9dIdWF2/Ywxq9aWpTm5/wXAImjzQGmpKRE119/vXw+n2w2m5YuXRoZC4VCmjFjhgYPHqzu3bvL5/Ppjjvu0O7d0f90q62tVUFBgVwul9LT0zVp0iTV19dH1axfv15XX321UlNTlZ2drblz57ZvhgCi2Kv26tWaS9u0ztamLKku2EEdAUDbtTnAHDhwQEOGDNH8+fOPGjt48KDWrVunBx54QOvWrdNrr72myspKfe9734uqKygo0MaNG1VcXKxly5appKREU6ZMiYwHg0GNHj1a/fr1U3l5uR577DE99NBDevbZZ9sxRQBRwi2yfdqtTc9FajF2ybT/Dr4AEGs2Y9r/qWSz2bRkyRLdeOONx6xZs2aNRowYoR07dqhv377avHmzBg0apDVr1mj48OGSpOXLl+u6667Trl275PP5tGDBAv3yl7+U3++Xw+GQJN1///1aunSptmzZ0ur7NDY2qrHx3/enCAaDys7O1jW6Qck2nt0CfJ29Rw8N/dEODUw5ua+SXtl3rpoWNUhh7sILoGM1m5BW6XUFAgG5XK5j1nX4OTCBQEA2m03p6emSpNLSUqWnp0fCiyTl5eXJbrerrKwsUjNy5MhIeJGk/Px8VVZWat++1h/EMnv2bLnd7sgrOzu74yYFWJxpbNT+lrSTrq+p70F4AZBQOjTANDQ0aMaMGbr11lsjKcrv9ysrKyuqLjk5WRkZGfL7/ZEaj8cTVXPk5yM13zRz5kwFAoHIq6qqKtbTAToN09KiTfv7nHx9rePERQBwGiV31IZDoZBuvvlmGWO0YMGCjnqbCKfTKafT2eHvA3QK4bCaPu2pplHNcthO/DGQdMh2GpoCgJPXIUdgjoSXHTt2qLi4OOo7LK/Xq5qamqj65uZm1dbWyuv1Rmqqq6ujao78fKQGwKnptmWvPjp08kdhACCRxDzAHAkvW7du1TvvvKPevaNvW56bm6u6ujqVl5dHlq1cuVLhcFg5OTmRmpKSEoVC/77jVnFxsQYMGKBevXrFumWgSzKhkAKhbiesa5FR8iGuQAKQWNocYOrr61VRUaGKigpJ0vbt21VRUaGdO3cqFArpBz/4gdauXavFixerpaVFfr9ffr9fTU2Hr3YYOHCgxowZo8mTJ2v16tX68MMPVVRUpAkTJsjn80mSbrvtNjkcDk2aNEkbN27UK6+8oqeeekpTp06N3cyBrs4Y1YVO/FiBFtOi1NqTv+QaAE6HNp8Ds3btWl177bWRn4+EiokTJ+qhhx7SG2+8IUm65JJLotZ79913dc0110iSFi9erKKiIo0aNUp2u13jx4/XvHnzIrVut1tvv/22CgsLNWzYMGVmZmrWrFlR94oBcIqMUe2XPaXMeDcCAG3X5gBzzTXX6Hi3jjmZ28pkZGTopZdeOm7NxRdfrPfff7+t7QFog9Qau3RBvLsAgLbjWUhAF9bd36T9bXwuEgAkAgIM0IXZa+q0tuGseLcBAG1GgAG6MNPYqE+39ztuTZItSQ29kk5TRwBwcggwQBfn+qdRk2k+5niSbGruxo3sACQWAgzQxTn3BPWv5hNfTg0AiYQAA3Rx4fp6vfsllyIBsBYCDNDVGaPG6mM/mTosIzsXKgFIMAQYAEr98nBQaU2zaVHal8c+RwYA4oEAA0Bpe5t08Bgn8n4Ztik52HCaOwKA4yPAAJA9eEBVzd1bHTsQdkoNfIcEILEQYAAofPCQPqtv/YZ2e0Lp0teeDA8AiYAAA0AKh7X3YI9Wh5JsYcnGfWAAJBYCDABJUkuNs9XlnuSAbCltfu4rAHQoAgwASZI5RkbxJjcodIbr9DYDACdAgAG6ILvbpdrvnKXm832RZS5Pfau1PWwpCp7Ns5AAJBYCDNDF2DJ6yXzf6O6LV+vg0MMn59qyMnVVr63HXOdYR2cAIF74WAK6EHu6W75bvtS13Wok2XRZ5g59lP8fGnT2Lp2fcuyb1SUf4iReAImFAAN0IV8N66lbu22WdDiQjEgNaMRFa064XurZ9bKVpchwOTWABMFXSEAXYUtO1nnn7pZdbT+acnvWeh0c5OmArgCgfQgwQBdhvL2V2317u9Z12JJ18FyehwQgcRBggC5if7ZDveyOdq+f5W79KiUAiAcCDNBFGK6EBtCJEGAAnJSw4UokAImDAAN0EalfhdVg2ncey56WFh1c545xRwDQflxGDXQRzm01+tO6K3TegC80LG2Heicd/k7pYPjwpdHd7ClK+sYVSgdMSG8Fz1ftR5lK27TrtPcMAMdCgAG6CBMKKX1Vlb76MEVv97pUB/ukSpLSvmySJB3KdCj8/z8RGjIlk2zk3io5/rVXzqYv4tU2ALSKAAN0MSYUkmq+VFpN9PK0r2WU7l+vPy1dAUDbcA4MAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwHAIMAACwnDYHmJKSEl1//fXy+Xyy2WxaunTpMWt/8pOfyGaz6cknn4xaXltbq4KCArlcLqWnp2vSpEmqr49+UNz69et19dVXKzU1VdnZ2Zo7d25bWwUAAJ1UmwPMgQMHNGTIEM2fP/+4dUuWLNHHH38sn8931FhBQYE2btyo4uJiLVu2TCUlJZoyZUpkPBgMavTo0erXr5/Ky8v12GOP6aGHHtKzzz7b1nYBAEAn1OYb2Y0dO1Zjx449bs0XX3yhu+++W2+99ZbGjRsXNbZ582YtX75ca9as0fDhwyVJTz/9tK677jr9/ve/l8/n0+LFi9XU1KTnnntODodDF154oSoqKvT4449HBZ2va2xsVGNjY+TnYDDY1qkBAACLiPk5MOFwWLfffrumT5+uCy+88Kjx0tJSpaenR8KLJOXl5clut6usrCxSM3LkSDkcjkhNfn6+KisrtW/fvlbfd/bs2XK73ZFXdnZ2jGcGAAASRcwDzKOPPqrk5GT97Gc/a3Xc7/crKysrallycrIyMjLk9/sjNR6PJ6rmyM9Har5p5syZCgQCkVdVVdWpTgUAACSomD4Lqby8XE899ZTWrVsnm8124hViyOl0yul0ntb3BAAA8RHTIzDvv/++ampq1LdvXyUnJys5OVk7duzQtGnTdPbZZ0uSvF6vamqinyLX3Nys2tpaeb3eSE11dXVUzZGfj9QAAICuK6YB5vbbb9f69etVUVERefl8Pk2fPl1vvfWWJCk3N1d1dXUqLy+PrLdy5UqFw2Hl5OREakpKShQKhSI1xcXFGjBggHr16hXLlgEAgAW1+Suk+vp6bdu2LfLz9u3bVVFRoYyMDPXt21e9e/eOqk9JSZHX69WAAQMkSQMHDtSYMWM0efJkLVy4UKFQSEVFRZowYULkkuvbbrtNDz/8sCZNmqQZM2Zow4YNeuqpp/TEE0+cylwBAEAn0eYAs3btWl177bWRn6dOnSpJmjhxohYtWnRS21i8eLGKioo0atQo2e12jR8/XvPmzYuMu91uvf322yosLNSwYcOUmZmpWbNmHfMSagAA0LXYjDEm3k10hGAwKLfbrWt0g5JtKfFuBwAAnIRmE9Iqva5AICCXy3XMOp6FBAAALIcAAwAALIcAAwAALIcAAwAALIcAAwAALIcAAwAALIcAAwAALIcAAwAALIcAAwAALIcAAwAALIcAAwAALIcAAwAALIcAAwAALCc53g10lCMP2W5WSOqUz9sGAKDzaVZI0r//Hj+WThtgvvrqK0nSB3ozzp0AAIC22r9/v9xu9zHHO22AycjIkCTt3LnzuP8BrCgYDCo7O1tVVVVyuVzxbiemmJs1dea5SZ17fszNmjrz3Iwx2r9/v3w+33HrOm2AsdsPn97jdrs73c49wuVyMTcLYm7W1Znnx9ysqbPO7WQOPHASLwAAsBwCDAAAsJxOG2CcTqcefPBBOZ3OeLcSc8zNmpibdXXm+TE3a+rMcztZNnOi65QAAAASTKc9AgMAADovAgwAALAcAgwAALAcAgwAALAcAgwAALCcThlg5s+fr7PPPlupqanKycnR6tWr493SCc2ePVuXXXaZevbsqaysLN14442qrKyMqrnmmmtks9miXj/5yU+ianbu3Klx48apW7duysrK0vTp09Xc3Hw6p3KUhx566Ki+L7jggsh4Q0ODCgsL1bt3b/Xo0UPjx49XdXV11DYScV6SdPbZZx81N5vNpsLCQknW2mclJSW6/vrr5fP5ZLPZtHTp0qhxY4xmzZqlPn36KC0tTXl5edq6dWtUTW1trQoKCuRyuZSenq5Jkyapvr4+qmb9+vW6+uqrlZqaquzsbM2dO7ejpybp+PMLhUKaMWOGBg8erO7du8vn8+mOO+7Q7t27o7bR2v6eM2dOVE085neifXfnnXce1feYMWOiahJ1351obq39/tlsNj322GORmkTcbyfzmR+rz8ZVq1Zp6NChcjqdOu+887Ro0aIOndtpYzqZl19+2TgcDvPcc8+ZjRs3msmTJ5v09HRTXV0d79aOKz8/3zz//PNmw4YNpqKiwlx33XWmb9++pr6+PlLzrW99y0yePNns2bMn8goEApHx5uZmc9FFF5m8vDzzySefmDfffNNkZmaamTNnxmNKEQ8++KC58MILo/reu3dvZPwnP/mJyc7ONitWrDBr1641l19+ubniiisi44k6L2OMqampiZpXcXGxkWTeffddY4y19tmbb75pfvnLX5rXXnvNSDJLliyJGp8zZ45xu91m6dKl5tNPPzXf+973TP/+/c2hQ4ciNWPGjDFDhgwxH3/8sXn//ffNeeedZ2699dbIeCAQMB6PxxQUFJgNGzaYv/zlLyYtLc0888wzcZ1fXV2dycvLM6+88orZsmWLKS0tNSNGjDDDhg2L2ka/fv3MI488ErU/v/47Gq/5nWjfTZw40YwZMyaq79ra2qiaRN13J5rb1+e0Z88e89xzzxmbzWY+//zzSE0i7reT+cyPxWfjP//5T9OtWzczdepUs2nTJvP000+bpKQks3z58g6b2+nS6QLMiBEjTGFhYeTnlpYW4/P5zOzZs+PYVdvV1NQYSea9996LLPvWt75lfv7znx9znTfffNPY7Xbj9/sjyxYsWGBcLpdpbGzsyHaP68EHHzRDhgxpdayurs6kpKSYV199NbJs8+bNRpIpLS01xiTuvFrz85//3Jx77rkmHA4bY6y7z775F0U4HDZer9c89thjkWV1dXXG6XSav/zlL8YYYzZt2mQkmTVr1kRq/v73vxubzWa++OILY4wxf/zjH02vXr2i5jZjxgwzYMCADp5RtNb+Ivym1atXG0lmx44dkWX9+vUzTzzxxDHXSYT5HSvA3HDDDcdcxyr77mT22w033GC+/e1vRy2zwn775md+rD4b77vvPnPhhRdGvdctt9xi8vPzO3pKHa5TfYXU1NSk8vJy5eXlRZbZ7Xbl5eWptLQ0jp21XSAQkPTvp2ofsXjxYmVmZuqiiy7SzJkzdfDgwchYaWmpBg8eLI/HE1mWn5+vYDCojRs3np7Gj2Hr1q3y+Xw655xzVFBQoJ07d0qSysvLFQqFovbZBRdcoL59+0b2WSLP6+uampr04osv6kc/+pFsNltkuVX32ddt375dfr8/aj+53W7l5ORE7af09HQNHz48UpOXlye73a6ysrJIzciRI+VwOCI1+fn5qqys1L59+07TbE5OIBCQzWZTenp61PI5c+aod+/euvTSS/XYY49FHa5P5PmtWrVKWVlZGjBggO666y599dVXkbHOsu+qq6v1f//3f5o0adJRY4m+3775mR+rz8bS0tKobRypsdrfia3pVE+j/vLLL9XS0hK1MyXJ4/Foy5Ytceqq7cLhsO655x5deeWVuuiiiyLLb7vtNvXr108+n0/r16/XjBkzVFlZqddee02S5Pf7W537kbF4ycnJ0aJFizRgwADt2bNHDz/8sK6++mpt2LBBfr9fDofjqL8kPB5PpOdEndc3LV26VHV1dbrzzjsjy6y6z77pSC+t9fr1/ZSVlRU1npycrIyMjKia/v37H7WNI2O9evXqkP7bqqGhQTNmzNCtt94a9aTfn/3sZxo6dKgyMjL00UcfaebMmdqzZ48ef/xxSYk7vzFjxuimm25S//799fnnn+t//ud/NHbsWJWWliopKanT7LsXXnhBPXv21E033RS1PNH3W2uf+bH6bDxWTTAY1KFDh5SWltYRUzotOlWA6SwKCwu1YcMGffDBB1HLp0yZEvnz4MGD1adPH40aNUqff/65zj333NPd5kkbO3Zs5M8XX3yxcnJy1K9fP/31r3+19C/PN/35z3/W2LFj5fP5Isusus+6slAopJtvvlnGGC1YsCBqbOrUqZE/X3zxxXI4HPrxj3+s2bNnJ/QzaSZMmBD58+DBg3XxxRfr3HPP1apVqzRq1Kg4dhZbzz33nAoKCpSamhq1PNH327E+83F8neorpMzMTCUlJR11lnZ1dbW8Xm+cumqboqIiLVu2TO+++67OOuus49bm5ORIkrZt2yZJ8nq9rc79yFiiSE9P13/8x39o27Zt8nq9ampqUl1dXVTN1/eZFea1Y8cOvfPOO/rv//7v49ZZdZ8d6eV4v1ter1c1NTVR483NzaqtrbXMvjwSXnbs2KHi4uKooy+tycnJUXNzs/71r39JSvz5HXHOOecoMzMz6v9Dq++7999/X5WVlSf8HZQSa78d6zM/Vp+Nx6pxuVyW/wdkpwowDodDw4YN04oVKyLLwuGwVqxYodzc3Dh2dmLGGBUVFWnJkiVauXLlUYczW1NRUSFJ6tOnjyQpNzdXn332WdQH0ZEP4UGDBnVI3+1RX1+vzz//XH369NGwYcOUkpIStc8qKyu1c+fOyD6zwryef/55ZWVlady4ccets+o+69+/v7xeb9R+CgaDKisri9pPdXV1Ki8vj9SsXLlS4XA4Etxyc3NVUlKiUCgUqSkuLtaAAQPi/hXEkfCydetWvfPOO+rdu/cJ16moqJDdbo98/ZLI8/u6Xbt26auvvor6/9DK+046fAR02LBhGjJkyAlrE2G/negzP1afjbm5uVHbOFKT6H8nnpQ4n0Qccy+//LJxOp1m0aJFZtOmTWbKlCkmPT096iztRHTXXXcZt9ttVq1aFXWp38GDB40xxmzbts088sgjZu3atWb79u3m9ddfN+ecc44ZOXJkZBtHLqkbPXq0qaioMMuXLzdnnHFG3C83njZtmlm1apXZvn27+fDDD01eXp7JzMw0NTU1xpjDlwr27dvXrFy50qxdu9bk5uaa3NzcyPqJOq8jWlpaTN++fc2MGTOillttn+3fv9988skn5pNPPjGSzOOPP24++eSTyFU4c+bMMenp6eb1118369evNzfccEOrl1FfeumlpqyszHzwwQfm/PPPj7oUt66uzng8HnP77bebDRs2mJdfftl069bttFxGfbz5NTU1me9973vmrLPOMhUVFVG/g0eu5vjoo4/ME088YSoqKsznn39uXnzxRXPGGWeYO+64I+7zO97c9u/fb+69915TWlpqtm/fbt555x0zdOhQc/7555uGhobINhJ1353o/0tjDl8G3a1bN7NgwYKj1k/U/Xaiz3xjYvPZeOQy6unTp5vNmzeb+fPncxl1Inv66adN3759jcPhMCNGjDAff/xxvFs6IUmtvp5//nljjDE7d+40I0eONBkZGcbpdJrzzjvPTJ8+PeqeIsYY869//cuMHTvWpKWlmczMTDNt2jQTCoXiMKN/u+WWW0yfPn2Mw+EwZ555prnlllvMtm3bIuOHDh0yP/3pT02vXr1Mt27dzPe//32zZ8+eqG0k4ryOeOutt4wkU1lZGbXcavvs3XffbfX/wYkTJxpjDl9K/cADDxiPx2OcTqcZNWrUUXP+6quvzK233mp69OhhXC6X+eEPf2j2798fVfPpp5+aq666yjidTnPmmWeaOXPmxH1+27dvP+bv4JF7+pSXl5ucnBzjdrtNamqqGThwoPnd734XFQLiNb/jze3gwYNm9OjR5owzzjApKSmmX79+ZvLkyUf9oy5R992J/r80xphnnnnGpKWlmbq6uqPWT9T9dqLPfGNi99n47rvvmksuucQ4HA5zzjnnRL2HldmMMaaDDu4AAAB0iE51DgwAAOgaCDAAAMByCDAAAMByCDAAAMByCDAAAMByCDAAAMByCDAAAMByCDAAAMByCDAAAMByCDAAAMByCDAAAMBy/h/mXFttxb4dhgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mask.cpu().numpy()>0)\n",
    "plt.imshow(label.cpu().numpy(), alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 8, 4096])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attns[-1][0][0,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4096, 8])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attns[1][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask Irregularity (PAUSED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imea, json, math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pycocotools.mask as mask_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask(path):\n",
    "    masks = json.load(open(path)) # load json masks\n",
    "    target = np.zeros((masks['image']['height'], masks['image']['width']), dtype=np.uint8)\n",
    "    for i, m in enumerate(masks['annotations'], 1):\n",
    "        mask = mask_utils.decode(m['segmentation'])==1\n",
    "        target[mask] = i\n",
    "    return target\n",
    "\n",
    "def get_mask_metrics(mask):\n",
    "    metrics = imea.shape_measurements_2d(mask).to_dict()\n",
    "    out = {}\n",
    "    out['solidity'] = metrics['area_projection'][0] / metrics['area_convex'][0]\n",
    "    out['convexity'] = metrics['convex_perimeter'][0] / metrics['perimeter'][0]\n",
    "    fibre_length = (metrics['perimeter'][0] - math.sqrt(metrics['perimeter'][0]**2 - 16 * metrics['area_projection'][0])) / 4\n",
    "    out['curl'] = metrics['major_axis_length'][0] / fibre_length\n",
    "    out['fractal_dimension'] = metrics['fractal_dimension_perimeter_method'][0]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_metrics(sample):\n",
    "    name = sample['name']\n",
    "    prompt = sample['prompt']\n",
    "    path = f\"../../Datasets/SA_1B/images/sa_000020/{name}.json\"\n",
    "    mask = get_mask(path)\n",
    "    mask = mask == mask[prompt[1], prompt[0]]\n",
    "    _, _, mask = get_mask_limits([mask])\n",
    "    metrics = get_mask_metrics(mask)\n",
    "\n",
    "    plt.imshow(mask)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    for k, v in metrics.items():\n",
    "        print(f\"{k}: {v:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.read_pickle(f\"../results/center_sa1b_prompts.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    mask_metrics(df_p.iloc[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
