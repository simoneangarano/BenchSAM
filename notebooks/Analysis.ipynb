{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from utils.utils import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "'EXPERIMENT': 'filter20_',\n",
    "'DATASET': 'sa1b',\n",
    "'MODEL': 'MobileSAM_kd',\n",
    "'TARGET': 'SAM',\n",
    "'SPARSITY': 0,\n",
    "'CLASS': 0,\n",
    "'MODE': '',\n",
    "'METRIC': 'iou'\n",
    "}\n",
    "cfg['ROOT'], cfg['N'], cfg['CLASSES'], cfg['SUPERCLASSES'], cfg['SUP_N'] = get_dataset_info(cfg['DATASET'])\n",
    "cfg['SUP_L'] = {v: k for k, v in cfg['SUP_N'].items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.read_pickle(f\"../results/{cfg['EXPERIMENT']}{cfg['DATASET']}_prompts.pkl\")\n",
    "df_0 = pd.read_pickle(f\"../results/{cfg['EXPERIMENT']}{cfg['DATASET']}_{cfg['TARGET']}_0.pkl\")\n",
    "df_s = pd.read_pickle(f\"../results/{cfg['EXPERIMENT']}{cfg['DATASET']}_{cfg['MODEL']}_{cfg['SPARSITY']}{cfg['MODE']}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>prompt</th>\n",
       "      <th>class</th>\n",
       "      <th>s_class</th>\n",
       "      <th>mask</th>\n",
       "      <th>mask_origin</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sa_231941</td>\n",
       "      <td>[70, 480]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'size': [1500, 2250], 'counts': b'h;]5_Y10000...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0.903239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sa_234721</td>\n",
       "      <td>[74, 1272]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'size': [1500, 2247], 'counts': b'gT1[4aZ1000...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0.898186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sa_234928</td>\n",
       "      <td>[1015, 932]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'size': [2250, 1500], 'counts': b'TSZl1g0\\\\U2...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0.899765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sa_227443</td>\n",
       "      <td>[2112, 902]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'size': [1500, 2250], 'counts': b'UVoo21h^1c0...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0.822798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sa_231190</td>\n",
       "      <td>[2056, 415]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'size': [1500, 2250], 'counts': b'ejVm27Q]10W...</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>0.815535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name       prompt class s_class  \\\n",
       "0  sa_231941    [70, 480]  None    None   \n",
       "1  sa_234721   [74, 1272]  None    None   \n",
       "2  sa_234928  [1015, 932]  None    None   \n",
       "3  sa_227443  [2112, 902]  None    None   \n",
       "4  sa_231190  [2056, 415]  None    None   \n",
       "\n",
       "                                                mask mask_origin     score  \n",
       "0  {'size': [1500, 2250], 'counts': b'h;]5_Y10000...      [0, 0]  0.903239  \n",
       "1  {'size': [1500, 2247], 'counts': b'gT1[4aZ1000...      [0, 0]  0.898186  \n",
       "2  {'size': [2250, 1500], 'counts': b'TSZl1g0\\\\U2...      [0, 0]  0.899765  \n",
       "3  {'size': [1500, 2250], 'counts': b'UVoo21h^1c0...      [0, 0]  0.822798  \n",
       "4  {'size': [1500, 2250], 'counts': b'ejVm27Q]10W...      [0, 0]  0.815535  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "operands could not be broadcast together with shapes (1500,2250) (1500,2247) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> 93\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     94\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/pandas/core/nanops.py:155\u001b[0m, in \u001b[0;36mbottleneck_switch.__call__.<locals>.f\u001b[0;34m(values, axis, skipna, **kwds)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 155\u001b[0m     result \u001b[39m=\u001b[39m alt(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    157\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/pandas/core/nanops.py:418\u001b[0m, in \u001b[0;36m_datetimelike_compat.<locals>.new_func\u001b[0;34m(values, axis, skipna, mask, **kwargs)\u001b[0m\n\u001b[1;32m    416\u001b[0m     mask \u001b[39m=\u001b[39m isna(values)\n\u001b[0;32m--> 418\u001b[0m result \u001b[39m=\u001b[39m func(values, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, mask\u001b[39m=\u001b[39;49mmask, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m datetimelike:\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/pandas/core/nanops.py:706\u001b[0m, in \u001b[0;36mnanmean\u001b[0;34m(values, axis, skipna, mask)\u001b[0m\n\u001b[1;32m    705\u001b[0m count \u001b[39m=\u001b[39m _get_counts(values\u001b[39m.\u001b[39mshape, mask, axis, dtype\u001b[39m=\u001b[39mdtype_count)\n\u001b[0;32m--> 706\u001b[0m the_sum \u001b[39m=\u001b[39m _ensure_numeric(values\u001b[39m.\u001b[39;49msum(axis, dtype\u001b[39m=\u001b[39;49mdtype_sum))\n\u001b[1;32m    708\u001b[0m \u001b[39mif\u001b[39;00m axis \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mgetattr\u001b[39m(the_sum, \u001b[39m\"\u001b[39m\u001b[39mndim\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/numpy/core/_methods.py:48\u001b[0m, in \u001b[0;36m_sum\u001b[0;34m(a, axis, dtype, out, keepdims, initial, where)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sum\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     47\u001b[0m          initial\u001b[39m=\u001b[39m_NoValue, where\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mreturn\u001b[39;00m umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1500,2250) (1500,2247) ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sa58728/BenchSAM/notebooks/Analysis.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bvita10.ece.utexas.edu/home/sa58728/BenchSAM/notebooks/Analysis.ipynb#Y232sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m df_s[\u001b[39m'\u001b[39m\u001b[39mmask\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m df_s\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m s: maskUtils\u001b[39m.\u001b[39;49mdecode(s[\u001b[39m'\u001b[39;49m\u001b[39mmask\u001b[39;49m\u001b[39m'\u001b[39;49m]), axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m.\u001b[39;49mmean()\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/pandas/core/generic.py:11847\u001b[0m, in \u001b[0;36mNDFrame._add_numeric_operations.<locals>.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11829\u001b[0m \u001b[39m@doc\u001b[39m(\n\u001b[1;32m  11830\u001b[0m     _num_doc,\n\u001b[1;32m  11831\u001b[0m     desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReturn the mean of the values over the requested axis.\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11845\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11846\u001b[0m ):\n\u001b[0;32m> 11847\u001b[0m     \u001b[39mreturn\u001b[39;00m NDFrame\u001b[39m.\u001b[39;49mmean(\u001b[39mself\u001b[39;49m, axis, skipna, level, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/pandas/core/generic.py:11401\u001b[0m, in \u001b[0;36mNDFrame.mean\u001b[0;34m(self, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11393\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmean\u001b[39m(\n\u001b[1;32m  11394\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m  11395\u001b[0m     axis: Axis \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m|\u001b[39m lib\u001b[39m.\u001b[39mNoDefault \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39mno_default,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11399\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m  11400\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Series \u001b[39m|\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m> 11401\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stat_function(\n\u001b[1;32m  11402\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mmean\u001b[39;49m\u001b[39m\"\u001b[39;49m, nanops\u001b[39m.\u001b[39;49mnanmean, axis, skipna, level, numeric_only, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m  11403\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/pandas/core/generic.py:11353\u001b[0m, in \u001b[0;36mNDFrame._stat_function\u001b[0;34m(self, name, func, axis, skipna, level, numeric_only, **kwargs)\u001b[0m\n\u001b[1;32m  11343\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m  11344\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing the level keyword in DataFrame and Series aggregations is \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m  11345\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdeprecated and will be removed in a future version. Use groupby \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  11348\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m  11349\u001b[0m     )\n\u001b[1;32m  11350\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_agg_by_level(\n\u001b[1;32m  11351\u001b[0m         name, axis\u001b[39m=\u001b[39maxis, level\u001b[39m=\u001b[39mlevel, skipna\u001b[39m=\u001b[39mskipna, numeric_only\u001b[39m=\u001b[39mnumeric_only\n\u001b[1;32m  11352\u001b[0m     )\n\u001b[0;32m> 11353\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_reduce(\n\u001b[1;32m  11354\u001b[0m     func, name\u001b[39m=\u001b[39;49mname, axis\u001b[39m=\u001b[39;49maxis, skipna\u001b[39m=\u001b[39;49mskipna, numeric_only\u001b[39m=\u001b[39;49mnumeric_only\n\u001b[1;32m  11355\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/pandas/core/series.py:4816\u001b[0m, in \u001b[0;36mSeries._reduce\u001b[0;34m(self, op, name, axis, skipna, numeric_only, filter_type, **kwds)\u001b[0m\n\u001b[1;32m   4812\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   4813\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mSeries.\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m does not implement \u001b[39m\u001b[39m{\u001b[39;00mkwd_name\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   4814\u001b[0m     )\n\u001b[1;32m   4815\u001b[0m \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(\u001b[39mall\u001b[39m\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 4816\u001b[0m     \u001b[39mreturn\u001b[39;00m op(delegate, skipna\u001b[39m=\u001b[39;49mskipna, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n",
      "File \u001b[0;32m~/anaconda3/envs/sam/lib/python3.9/site-packages/pandas/core/nanops.py:100\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     95\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     98\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     99\u001b[0m     \u001b[39mif\u001b[39;00m is_object_dtype(args[\u001b[39m0\u001b[39m]):\n\u001b[0;32m--> 100\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(e) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    101\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: operands could not be broadcast together with shapes (1500,2250) (1500,2247) "
     ]
    }
   ],
   "source": [
    "df_s['mask'] = df_s.apply(lambda s: maskUtils.decode(s['mask']), axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = df_s.iloc[0]['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'size': [1500, 2250],\n",
       " 'counts': b'h;]5_Y10000000010O01O00010O000010O1O1O103L3PK[fNc4QZ1N100O00001O00001O00001O001O001O000000001O000000001O0000001O001O1O1O2N1O100O001O00001O001O001O00001O00001O00001O0000001O000000001O0000001O000000001O000000000O2O00001O0O101O0O2O0O2N2O0O2N2N2O1N3N1N3N2M2O1N2O1N2O1N101N1O101N1O2N101N1O2N1O1O100O1O2M2O1O1N2N3M2O1N2N3N1N2O1O2N1O1O1O100O1O101N1O100O2N100O2O0O2O0O2O1N2M4L6I\\\\Win2'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycocotools import mask as maskUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maskUtils.decode(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask2rle(img):\n",
    "    \"\"\"\n",
    "    img: numpy array, 1 - mask, 0 - background\n",
    "    Returns run length as string formatted\n",
    "    \"\"\"\n",
    "    pixels = img.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return ' '.join(str(x) for x in runs)\n",
    "\n",
    "def rle2mask(mask_rle: str, label=1, shape=None):\n",
    "    \"\"\"\n",
    "    mask_rle: run-length as string formatted (start length)\n",
    "    shape: (height,width) of array to return\n",
    "    Returns numpy array, 1 - mask, 0 - background\n",
    "\n",
    "    \"\"\"\n",
    "    s = mask_rle.split()\n",
    "    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = label\n",
    "    return img.reshape(shape)  # Needed to align to RLE direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rle = mask2rle(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rle = maskUtils.encode(np.asfortranarray(m))\n",
    "#rle = str(rle['counts'], encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getsizeof(rle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(maskUtils.decode(rle) == m).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p['score'] = df_p.apply(lambda x: 0, axis=1)\n",
    "df_p['s_class'] = df_p.apply(lambda x: None, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mask_size(s, df=None):\n",
    "    if df is not None:\n",
    "        imsize = df[df['name']==s['name']]['shape'].values[0]\n",
    "    else:\n",
    "        imsize = s['shape']\n",
    "    return np.sum(s['mask']) / (imsize[0] * imsize[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p['mask_size'] = df_p.apply(get_mask_size, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.hist(column='mask_size', bins=100, cumulative=True, density=True)\n",
    "plt.semilogx()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in range(0, 110, 10):\n",
    "    print(f'{p}\\t{np.percentile(df_p[\"mask_size\"], p):.1e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0['mask_size'] = df_0.apply(lambda s: get_mask_size(s, df_p), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0.hist(column='mask_size', bins=100, cumulative=True, density=True)\n",
    "plt.semilogx()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 900\n",
    "plt.imshow(get_image(df_p['name'][i], cfg))\n",
    "plt.scatter(*df_p['prompt'][i], c='y', s=50)\n",
    "plt.imshow(get_full_mask(df_s['mask'][i], df_s['mask_origin'][i], df_p['shape'][i]), alpha=0.6, cmap='Blues')\n",
    "plt.imshow(get_full_mask(df_0['mask'][i], df_0['mask_origin'][i], df_p['shape'][i]), alpha=0.6, cmap='Reds')\n",
    "plt.imshow(get_full_mask(df_p['mask'][i], df_p['mask_origin'][i], df_p['shape'][i]), alpha=0.6, cmap='Greens')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Image Shape\n",
    "if 'shape' not in df_p.keys():\n",
    "    df_p = add_image_shape(df_p, cfg)\n",
    "    df_p.head()\n",
    "    df_p.to_pickle(f\"../results/{cfg['EXPERIMENT']}{cfg['DATASET']}_prompts.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT vs SAM\n",
    "df_g0 = get_analytics(df_p, df_0, df_p, cfg, skip_empty=True)\n",
    "df_g0.to_pickle(f\"../results/analytics/{cfg['EXPERIMENT']}{cfg['DATASET']}_{cfg['TARGET']}_{cfg['SPARSITY']}{cfg['MODE']}.pkl\")\n",
    "df_g0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_g0 = pd.read_pickle(f\"../results/analytics/{cfg['EXPERIMENT']}{cfg['DATASET']}_{cfg['TARGET']}_{cfg['SPARSITY']}{cfg['MODE']}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GT vs MobileSAM\n",
    "df_gs = get_analytics(df_p, df_s, df_p, cfg, skip_empty=True)\n",
    "df_gs.to_pickle(f\"../results/analytics/{cfg['EXPERIMENT']}{cfg['DATASET']}_{cfg['MODEL']}_{cfg['SPARSITY']}{cfg['MODE']}.pkl\")\n",
    "df_gs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_p) - len(df_gs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM\n",
    "df_g0.hist(column='iou')\n",
    "plt.semilogy()\n",
    "plt.show()\n",
    "df_g0['iou'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mobile\n",
    "df_gs.hist(column='iou')\n",
    "plt.semilogy()\n",
    "plt.show()\n",
    "df_gs['iou'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IoU_BCE\n",
    "df_gs.hist(column='iou')\n",
    "plt.semilogy()\n",
    "plt.show()\n",
    "df_gs['iou'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAM\n",
    "df_g0.hist(column='mask_size_diff')\n",
    "plt.semilogy()\n",
    "plt.show()\n",
    "df_g0['mask_size_diff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mobile\n",
    "df_gs.hist(column='mask_size_diff')\n",
    "plt.semilogy()\n",
    "plt.show()\n",
    "df_gs['mask_size_diff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IOU_BCE\n",
    "df_gs.hist(column='mask_size_diff')\n",
    "plt.semilogy()\n",
    "plt.show()\n",
    "df_gs['mask_size_diff'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Save Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_analytics(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_summary(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_summary(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for s in range(10, 100, 10):\n",
    "#     cfg['SPARSITY'] = s\n",
    "#     save_analytics(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Summary\n",
    "summary = []\n",
    "for m in MODES:\n",
    "    cfg['MODE'] = m\n",
    "    for s in SPARSITIES:\n",
    "        cfg['SPARSITY'] = s\n",
    "        summary.append(get_summary(cfg))\n",
    "\n",
    "cfg['MODE'] = ''\n",
    "cfg['SPARSITY'] = 0\n",
    "for n in MODELS[1:]:\n",
    "    cfg['MODEL'] = n\n",
    "    summary.append(get_summary(cfg))\n",
    "summary = pd.concat(summary)\n",
    "summary.to_pickle(f\"analytics/{cfg['EXPERIMENT']}{cfg['DATASET']}_summary.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histograms\n",
    "for t in METRICS:\n",
    "    cfg['METRIC'] = t\n",
    "    for m in MODES:\n",
    "        cfg['MODE'] = m\n",
    "        summary = []\n",
    "        for s in SPARSITIES:\n",
    "            cfg['SPARSITY'] = s\n",
    "            summary.append(get_summary(cfg))\n",
    "        summary = pd.concat(summary)\n",
    "        get_hists(summary, cfg, save=True, plot=True)\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg['MODE'] = ''\n",
    "cfg['SPARSITY'] = 0\n",
    "for t in METRICS:\n",
    "    cfg['METRIC'] = t\n",
    "    summary = []\n",
    "    for n in MODELS[1:]:\n",
    "        cfg['MODEL'] = n\n",
    "        summary.append(get_summary(cfg))\n",
    "    summary = pd.concat(summary)\n",
    "    get_hists(summary, cfg, save=True, plot=True)\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_pickle(f\"analytics/{cfg['EXPERIMENT']}{cfg['DATASET']}_summary.pkl\")\n",
    "\n",
    "for m in METRICS:\n",
    "    cfg['METRIC'] = m\n",
    "    get_curves(summary, cfg, std=False, plot=True, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class-wise Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Summary\n",
    "summary = []\n",
    "for m in MODES:\n",
    "    cfg['MODE'] = m\n",
    "    for s in SPARSITIES:\n",
    "        cfg['SPARSITY'] = s\n",
    "        summary.append(get_summary(cfg, classwise=True))\n",
    "\n",
    "cfg['MODE'] = ''\n",
    "cfg['SPARSITY'] = 0\n",
    "for n in MODELS[1:]:\n",
    "    cfg['MODEL'] = n\n",
    "    summary.append(get_summary(cfg, classwise=True))\n",
    "summary = pd.concat(summary)\n",
    "summary.to_pickle(f\"analytics/{cfg['EXPERIMENT']}{cfg['DATASET']}_classwise.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = summary[summary['pruning']=='_gup']\n",
    "d = d[d['id']==50]\n",
    "d = d[d['class']!=0]\n",
    "get_hists(d, cfg, save=False, plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class-wise Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_pickle(f\"analytics/{cfg['EXPERIMENT']}{cfg['DATASET']}_classwise.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classwise_curves(d, cfg, plot=True, save=False):\n",
    "    _, ax = plt.subplots()\n",
    "    ax.grid()\n",
    "    ax.title.set_text(cfg['METRIC'].replace('_', ' ').capitalize())\n",
    "    ax.plot(PARAMS['SAM'], SAM[cfg['METRIC']], 'o')\n",
    "     \n",
    "    for c in range(1, d.shape[1]):\n",
    "        if cfg['MODEL'] == 'SAM':\n",
    "            p = (1 - d[:,c,1]/100) * PARAMS['SAM'] \n",
    "        else:\n",
    "            p = PARAMS[d[:,c,1][0]]\n",
    "        ax.plot(p, d[:,c,2], '-o', label=f\"{cfg['SUP_L'][c]} ({d[0,c,3]})\")\n",
    "    # Shrink current axis's height by 10% on the bottom\n",
    "    box = ax.get_position()\n",
    "    ax.set_position([box.x0, box.y0 + box.height * 0.1, box.width, box.height * 0.9])\n",
    "    ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), fancybox=False, shadow=False, ncol=4, fontsize=9)   \n",
    "    #plt.legend(loc='best', fontsize=9, ncol=2)\n",
    "    plt.xlabel('Parameters')\n",
    "    plt.ylabel(cfg['METRIC'].replace('_', ' ').capitalize())\n",
    "    plt.axvline(PARAMS['SAM'], linestyle='--')\n",
    "    plt.axhline(SAM[cfg['METRIC']], linestyle='--')\n",
    "    plt.semilogx()\n",
    "    if save:\n",
    "        plt.savefig(f\"figures/{cfg['EXPERIMENT']}{cfg['DATASET']}_{cfg['METRIC']}_{cfg['MODEL']}{cfg['MODE']}_curves_classwise.pdf\", bbox_inches='tight')\n",
    "    if plot:\n",
    "        plt.show()\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GUP\n",
    "for m in METRICS:\n",
    "    cfg['METRIC'] = m\n",
    "    d = summary[summary['pruning']=='_gup'][['class', 'id', cfg['METRIC'], 'n']].values.reshape(9, 13, -1)\n",
    "    get_classwise_curves(d, cfg, plot=True, save=True)\n",
    "\n",
    "# SparseGPT\n",
    "cfg['MODE'] = '_gup'\n",
    "for m in METRICS:\n",
    "    cfg['METRIC'] = m\n",
    "    d = summary[summary['id'].str.isalpha().isnull()]\n",
    "    d = d[d['pruning']!='_gup'][['class', 'id', cfg['METRIC'], 'n']].values.reshape(9, 13, -1)\n",
    "    get_classwise_curves(d, cfg, plot=True, save=True)\n",
    "\n",
    "# FastSAM\n",
    "# cfg['MODEL'] = 'FastSAM'\n",
    "# for m in METRICS:\n",
    "#     cfg['METRIC'] = m\n",
    "#     d = summary[summary['id']==cfg['MODEL']][['class', 'id', cfg['METRIC'], 'n']].values.reshape(1, 13, -1)\n",
    "#     get_classwise_curves(d, cfg, plot=True, save=True)\n",
    "\n",
    "# MobileSAM\n",
    "# cfg['MODEL'] = 'MobileSAM'\n",
    "# for m in METRICS:\n",
    "#     cfg['METRIC'] = m\n",
    "#     d = summary[summary['id']==cfg['MODEL']][['class', 'id', cfg['METRIC'], 'n']].values.reshape(1, 13, -1)\n",
    "#     get_classwise_curves(d, cfg, plot=True, save=True)\n",
    "\n",
    "# Mobile&FastSAM\n",
    "cfg['MODEL'] = 'Mobile&FastSAM'\n",
    "for m in METRICS:\n",
    "    cfg['METRIC'] = m\n",
    "    d = summary[summary['id'].str.isalpha().notnull()][['class', 'id', cfg['METRIC'], 'n']].values.reshape(1, 13, -1)\n",
    "    get_classwise_curves(d, cfg, plot=True, save=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forgettability_curve_dissimilarity(d, cfg, plot=True, save=False):\n",
    "    fcd = np.zeros((d.shape[1], d.shape[1]))\n",
    "    for c1 in range(d.shape[1]):\n",
    "        for c2 in range(c1, d.shape[1]):\n",
    "            if c1 == c2:\n",
    "                continue\n",
    "            fcd[c1, c2] = ((d[:,c1,2] - d[:,c2,2])**2).mean()\n",
    "            fcd[c2, c1] = fcd[c1, c2]\n",
    "\n",
    "    plt.imshow(fcd, interpolation='nearest')\n",
    "    plt.xticks(range(12), [cfg['SUP_L'][i] for i in range(1, 13)], rotation=90)\n",
    "    plt.yticks(range(12), [cfg['SUP_L'][i] for i in range(1, 13)])\n",
    "    plt.title('Forgettability Curve Dissimilarity - GUP')\n",
    "    plt.colorbar()\n",
    "    if save:\n",
    "        plt.savefig(f\"figures/{cfg['EXPERIMENT']}{cfg['DATASET']}{cfg['MODE']}_fcd.pdf\", bbox_inches='tight')\n",
    "    if plot:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg['MODE'] == '':\n",
    "    # SparseGPT\n",
    "    d = summary[summary['id'].str.isalpha().isnull()]\n",
    "    d = d[d['pruning']!='_gup'][['class', 'id', cfg['METRIC'], 'n']].values.reshape(9, 13, -1)[:,1:,:]\n",
    "elif cfg['MODE'] == '_gup':\n",
    "    # GUP\n",
    "    d = summary[summary['pruning']=='_gup'][['class', 'id', cfg['METRIC']]].values.reshape(9, 13, -1)[:,1:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_forgettability_curve_dissimilarity(d, cfg, plot=True, save=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"analytics/{cfg['EXPERIMENT']}{cfg['DATASET']}_{cfg['MODEL']}_{cfg['SPARSITY']}{cfg['MODE']}.pkl\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(column='iou')\n",
    "plt.semilogy()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_superclass(df, cfg)\n",
    "df['mask_size_target'] = (df['mask_size'] - df['mask_size_diff'] * 1e-5) / (1 + df['mask_size_diff'])\n",
    "df['f1'] = 2 * df['precision'] * df['recall'] / (df['precision'] + df['recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['iou', 'precision', 'recall', 'mask_size', 'mask_size_diff', 'superclass']\n",
    "data = df[features].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cluster'] = get_clusters(data, cfg, plot=True, save=False)\n",
    "#df.to_pickle(f\"analytics/{cfg['EXPERIMENT']}{cfg['DATASET']}_{cfg['MODEL']}_{cfg['SPARSITY']}{cfg['MODE']}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "def prod(l1, l2):\n",
    "   return list(product(l1, l2))\n",
    "\n",
    "M = ['iou', 'precision', 'recall']\n",
    "\n",
    "fig, axs = plt.subplots(3, 3, sharex=True, sharey='row', figsize=(10,8))\n",
    "for (ax, (c,m)) in zip(axs.flat, prod(range(3), M)):\n",
    "    y, x = np.histogram(df[df['cluster']==c][m])\n",
    "    ax.bar(x[:-1], y, width=x[1]-x[0], alpha=1)\n",
    "    ax.set_title(f\"[{c}] {m}\", fontsize=10)\n",
    "    ax.semilogy()\n",
    "plt.suptitle(f\"{cfg['MODEL']} {cfg['MODE']}\", fontsize=12)\n",
    "plt.savefig(f\"figures/{cfg['EXPERIMENT']}{cfg['DATASET']}_{cfg['MODEL']}_{cfg['SPARSITY']}{cfg['MODE']}_clusters.pdf\", bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **ID**       |**0**|**1**|**2**|\n",
    "--------------|-----|-----|-----|\n",
    "*SAM_40gup_20*|R    |IoU  |P    |\n",
    "*SAM_80_20*   |P    |R    |IoU  |\n",
    "*MobileSAM_20*|IoU  |R    |P    |\n",
    "*FastSAM_20*  |R    |IoU  |P    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"analytics/{cfg['EXPERIMENT']}{cfg['DATASET']}_{cfg['MODEL']}_{cfg['SPARSITY']}{cfg['MODE']}.pkl\")\n",
    "df_0 = pd.read_pickle(f\"results/{cfg['EXPERIMENT']}{cfg['DATASET']}_{cfg['TARGET']}_0.pkl\")\n",
    "df_s = pd.read_pickle(f\"results/{cfg['EXPERIMENT']}{cfg['DATASET']}_{cfg['MODEL']}_{cfg['SPARSITY']}{cfg['MODE']}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 2\n",
    "N = int(0.05*len(df))\n",
    "df_c = df[df['cluster']==C]\n",
    "min_iou = df_c.nsmallest(N, ['iou'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c['iou'].mean(), min_iou['iou'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_samples(pie_df=min_iou, target_df=df_0, pred_df=df_s, cfg=cfg, prompt_zoom=False, n=5, random=True, save=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(f\"../results/analytics/{cfg['EXPERIMENT']}{cfg['DATASET']}_{cfg['MODEL']}_{cfg['SPARSITY']}{cfg['MODE']}.pkl\")\n",
    "df_0 = pd.read_pickle(f\"../results/{cfg['EXPERIMENT']}{cfg['DATASET']}_{cfg['TARGET']}_0.pkl\")\n",
    "df_s = pd.read_pickle(f\"../results/{cfg['EXPERIMENT']}{cfg['DATASET']}_{cfg['MODEL']}_{cfg['SPARSITY']}{cfg['MODE']}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out SAM's wrong masks (out of prompt)\n",
    "df_0['check'] = df_0.apply(lambda s: check_prompt(s), axis=1)\n",
    "df_0.hist(column='check', range=(0,.1))\n",
    "\n",
    "df_0 = df_0[df_0['check']!=0]\n",
    "df = df[(df.name.isin(df_0.name))]\n",
    "df_s = df_s[(df_s.name.isin(df_0.name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s['check'] = df_s.apply(lambda s: check_prompt(s), axis=1)\n",
    "df_s.hist(column='check', range=(0,.1))\n",
    "\n",
    "df_s = df_s[df_s['check']!=0]\n",
    "df = df[(df.name.isin(df_s.name))]\n",
    "df_0 = df_0[(df_0.name.isin(df_s.name))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mask_size_target'] = (df['mask_size'] - df['mask_size_diff'] * 1e-5) / (1 + df['mask_size_diff'])\n",
    "df['f1'] = 2 * df['precision'] * df['recall'] / (df['precision'] + df['recall'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = int(0.1*len(df))\n",
    "min_iou = df.nsmallest(N, ['iou']) # [df['iou']>0.001]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.ones_like(df['mask_size_target']) / len(df['mask_size_target'])\n",
    "df.hist(column='mask_size_target', range=(0,1), weights=weights, cumulative=True, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.ones_like(min_iou['mask_size_target']) / len(min_iou['mask_size_target'])\n",
    "min_iou.hist(column='mask_size_target', range=(0,1), weights=weights, cumulative=True, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df))\n",
    "print(len(df[df['mask_size_diff'] < -0.5]) / len(df) * 100)\n",
    "print(len(df[df['mask_size_diff'] > 0.5]) / len(df) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(min_iou))\n",
    "print(len(min_iou[min_iou['mask_size_diff'] < -0.5]) / len(min_iou) * 100)\n",
    "print(len(min_iou[min_iou['mask_size_diff'] > 0.5]) / len(min_iou) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_iou.hist(column='mask_size', bins=100)\n",
    "plt.semilogy()\n",
    "plt.ylim(1, 350)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_iou.sort_values(by=['f1'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_samples(pie_df=min_iou, target_df=df_0, pred_df=df_s, cfg=cfg, prompt_zoom=False, thr=50, n=10, random=True, save=False, zoom=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with Ground Truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pycocotools import mask as mask_utils\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.read_pickle(f\"../results/{cfg['EXPERIMENT']}{cfg['DATASET']}_prompts.pkl\")\n",
    "df_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anns(name, cfg):\n",
    "    ann_path = cfg['ROOT'].joinpath(f\"sa_000020/{name}.json\")\n",
    "    with open(ann_path, 'r') as ann_path:\n",
    "        return json.load(ann_path)\n",
    "    \n",
    "def prompt_in_bbox(prompt, bbox):\n",
    "    return prompt[0] > bbox[0] and prompt[1] > bbox[1] and prompt[0] < bbox[0]+bbox[2] and prompt[1] < bbox[1]+bbox[3]\n",
    "\n",
    "def prompt_in_mask(prompt, ann):\n",
    "    if prompt_in_bbox(prompt, ann['bbox']):\n",
    "        mask = mask_utils.decode(ann['segmentation'])\n",
    "        if mask[prompt[1], prompt[0]]:\n",
    "            return mask\n",
    "    return\n",
    "\n",
    "def get_ground_truth_mask(s, cfg):\n",
    "    prompt = s['prompt']\n",
    "    anns = get_anns(s['name'], cfg)['annotations']\n",
    "    for ann in anns:\n",
    "        mask = prompt_in_mask(prompt, ann)\n",
    "        if mask is not None:\n",
    "            return mask.astype(bool)\n",
    "    print(s['name'], ' No mask found')\n",
    "    return np.zeros((s['shape'][0], s['shape'][1])).astype(bool)\n",
    "\n",
    "def get_ground_truth(df, cfg):\n",
    "    df['gt'] = df.apply(lambda s: get_mask_limits([get_ground_truth_mask(s, cfg)]), axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = get_ground_truth(df_p, cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p['gt_origin'] = df_p.apply(lambda s: s['gt_origin'][::-1], axis=1)\n",
    "#df_p['gt'] = df_p.apply(lambda s: s['gt'][2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(df_p['gt'][900])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(get_full_mask(df_p['gt'][900], df_p['gt_origin'][900], df_p['shape'][900]), alpha=0.6, cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.to_pickle(f\"../results/{cfg['EXPERIMENT']}{cfg['DATASET']}_prompts.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_wrong_prompt(s, cfg):\n",
    "    if not s['mask'].any():\n",
    "        print(s['name'])\n",
    "        #show_points_on_image(get_image(s['name'], cfg), [s['prompt']], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p.apply(lambda s: plot_wrong_prompt(s, cfg), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p[df_p['name']=='sa_229068']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g0[df_g0['name']=='sa_229068']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g0.sort_values(by=['mask_size'], ascending=True, inplace=True)\n",
    "df_g0.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('../Datasets/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prompt(label):\n",
    "    show_points_on_image(label.bool(), [[0,0]], input_labels=None)\n",
    "    e = cv2.Canny(image=label.numpy().astype(np.uint8), threshold1=10, threshold2=50)\n",
    "    e = cv2.dilate(e, np.ones((10, 10), np.uint8), iterations = 1).astype(bool)\n",
    "    label[e] = 0\n",
    "    C = np.unique(label)[1:]\n",
    "    if len(C) == 0:\n",
    "        c = 0\n",
    "    else:\n",
    "        c = np.random.choice(C)\n",
    "    x_v, y_v = np.where(label == c)\n",
    "    r = random.randint(0, len(x_v) - 1)\n",
    "    x, y = x_v[r], y_v[r]\n",
    "    show_points_on_image(label.bool(), [[y,x]], input_labels=None)\n",
    "\n",
    "    return [[[y,x]]], c # inverted to compensate different indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = COCOSegmentation(root=data_dir.joinpath('coco-2017/'), split='val', crop_size=0)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, \n",
    "                                         num_workers=4, pin_memory=True, worker_init_fn=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, (i, l, n) in enumerate(dataloader):\n",
    "    prompt, p_class = get_prompt(l[0])\n",
    "    print(prompt)\n",
    "    #if l[0][prompt[0][0][1], prompt[0][0][0]] == 0 and l[0].any():\n",
    "    print(n)\n",
    "    plt.imshow(i[0])\n",
    "    plt.imshow(l[0].bool(), alpha=.5)\n",
    "    show_points_and_masks_on_image(i[0], l.bool(), prompt[0], input_labels=None, zoom=True, prompt_zoom=True, thr=20, save=None)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_image = Image.open(data_dir.joinpath('coco-2017/val2017/000000000139.jpg')).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SamModel.from_pretrained(\"facebook/sam-vit-huge\").to(device)\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_points = [[[514, 216]]]\n",
    "show_points_on_image(raw_image, input_points[0])\n",
    "\n",
    "inputs = processor(raw_image, input_points=input_points, return_tensors=\"pt\").to(device)\n",
    "image_embeddings = model.get_image_embeddings(inputs[\"pixel_values\"])\n",
    "\n",
    "\n",
    "inputs.pop(\"pixel_values\", None) # pixel_values are no more needed\n",
    "inputs.update({\"image_embeddings\": image_embeddings})\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks = processor.image_processor.post_process_masks(outputs.pred_masks.cpu(), inputs[\"original_sizes\"].cpu(), inputs[\"reshaped_input_sizes\"].cpu())[0]\n",
    "scores = outputs.iou_scores\n",
    "show_masks_on_image(raw_image, masks, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_sam = masks[0,scores.argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(raw_image)\n",
    "plt.imshow(mask_sam, alpha=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"vit_t\"\n",
    "sam_checkpoint = \"bin/mobile_sam.pt\"\n",
    "\n",
    "model = sam_model_registry[model_type](checkpoint=sam_checkpoint).to(device).eval()\n",
    "predictor = SamPredictor(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_label = np.array([1])\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictor.set_image(np.array(raw_image))\n",
    "    masks, scores, _ = predictor.predict(np.array(input_points[0]), input_label)\n",
    "\n",
    "plt.imshow(raw_image)\n",
    "plt.imshow(mask_sam, alpha=0.5)\n",
    "plt.imshow(masks[np.argmax(scores)], alpha=0.5)\n",
    "plt.scatter(input_points[0][0][0], input_points[0][0][1], c='r', s=10)\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = pd.read_pickle(f\"results/{cfg['EXPERIMENT']}{cfg['DATASET']}_{cfg['TARGET']}_0.pkl\")\n",
    "df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0['check'] = df_0.apply(lambda s: check_prompt(s), axis=1)\n",
    "df_invalid = df_0[df_0['check']==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0.hist(column='check', range=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_invalid = df_0[df_0['check']==0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_samples(pie_df=df_invalid, target_df=df_0, pred_df=df_s, cfg=cfg, prompt_zoom=True, n=5, random=True, save=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
