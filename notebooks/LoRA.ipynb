{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LoRA Baseline for MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import torch\n",
    "from transformers import SamModel, SamProcessor\n",
    "from utils.mobile_sam import sam_model_registry\n",
    "from utils.mobile_sam.predictor import SamPredictor\n",
    "from utils.datasets import SA1B_Dataset\n",
    "from utils.utils import *\n",
    "from utils.distill_utils import *\n",
    "\n",
    "from minlora import (add_lora, apply_to_lora, disable_lora, enable_lora, get_lora_params, get_lora_state_dict,\n",
    "                     merge_lora, name_is_lora, remove_lora, load_multiple_lora, select_lora, LoRAParametrization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config_distillation.yaml', 'r') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.FullLoader)\n",
    "cfg['DATA_DIR'] = Path('../').joinpath(cfg['DATA_DIR'])\n",
    "cfg['OUTPUT_DIR'] = Path('../').joinpath(cfg['OUTPUT_DIR'])\n",
    "cfg['MODEL_DIR'] = Path('../').joinpath(cfg['MODEL_DIR'])\n",
    "cfg['PROMPT_DIR'] = cfg['OUTPUT_DIR'].joinpath(f\"prompts.pkl\")\n",
    "cfg['DEVICE'] = torch.device(f\"cuda:{cfg['GPU']}\" if torch.cuda.is_available() else \"cpu\")\n",
    "cfg['PRETRAINED'] = True if cfg['MODE'] in ['decoder', 'prompt'] else False\n",
    "\n",
    "# DATASET\n",
    "dataset = SA1B_Dataset(root=cfg['DATA_DIR'], split=[\"sa_00000\" + str(i) for i in range(cfg['TRAIN_SPLITS'])],\n",
    "                        features=None, labels=True)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=cfg['SHUFFLE'], num_workers=cfg['WORKERS'], pin_memory=False)\n",
    "test_dataset = SA1B_Dataset(root=cfg['DATA_DIR'], split=[cfg['SPLIT']], \n",
    "                            features=None, labels=True, max_samples=cfg['MAX_TEST'])\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=cfg['WORKERS'], pin_memory=False)\n",
    "\n",
    "# MODEL\n",
    "teacher = SamModel.from_pretrained(\"facebook/sam-vit-huge\").to(cfg['DEVICE'])\n",
    "teacher.eval()\n",
    "processor = SamProcessor.from_pretrained(\"facebook/sam-vit-huge\")\n",
    "sam_checkpoint = cfg['MODEL_DIR'].joinpath(cfg['CKPT']) if cfg['PRETRAINED'] else None\n",
    "model = sam_model_registry[\"vit_t\"](checkpoint=sam_checkpoint, add_prompt=cfg['ADD_PROMPT']) #.to(cfg['DEVICE'])\n",
    "model.eval()\n",
    "for m in model.image_encoder.modules():\n",
    "    if isinstance(m, torch.nn.BatchNorm2d):\n",
    "        m.eval()\n",
    "        m.weight.requires_grad_(False)\n",
    "        m.bias.requires_grad_(False)\n",
    "student = SamPredictor(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mask_decoder.transformer.layers.0.self_attn.q_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.0.self_attn.q_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.0.self_attn.k_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.0.self_attn.k_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.0.self_attn.v_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.0.self_attn.v_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.0.self_attn.out_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.0.self_attn.out_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.0.mlp.lin1.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.0.mlp.lin1.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.0.mlp.lin2.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.0.mlp.lin2.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.1.self_attn.q_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.1.self_attn.q_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.1.self_attn.k_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.1.self_attn.k_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.1.self_attn.v_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.1.self_attn.v_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.1.self_attn.out_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.1.self_attn.out_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.1.mlp.lin1.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.1.mlp.lin1.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.1.mlp.lin2.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.1.mlp.lin2.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.final_attn_token_to_image.q_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.final_attn_token_to_image.q_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.final_attn_token_to_image.k_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.final_attn_token_to_image.k_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.final_attn_token_to_image.v_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.final_attn_token_to_image.v_proj.parametrizations.weight.0.lora_B', 'mask_decoder.transformer.final_attn_token_to_image.out_proj.parametrizations.weight.0.lora_A', 'mask_decoder.transformer.final_attn_token_to_image.out_proj.parametrizations.weight.0.lora_B', 'mask_decoder.output_hypernetworks_mlps.0.layers.0.parametrizations.weight.0.lora_A', 'mask_decoder.output_hypernetworks_mlps.0.layers.0.parametrizations.weight.0.lora_B', 'mask_decoder.output_hypernetworks_mlps.0.layers.1.parametrizations.weight.0.lora_A', 'mask_decoder.output_hypernetworks_mlps.0.layers.1.parametrizations.weight.0.lora_B', 'mask_decoder.output_hypernetworks_mlps.0.layers.2.parametrizations.weight.0.lora_A', 'mask_decoder.output_hypernetworks_mlps.0.layers.2.parametrizations.weight.0.lora_B', 'mask_decoder.output_hypernetworks_mlps.1.layers.0.parametrizations.weight.0.lora_A', 'mask_decoder.output_hypernetworks_mlps.1.layers.0.parametrizations.weight.0.lora_B', 'mask_decoder.output_hypernetworks_mlps.1.layers.1.parametrizations.weight.0.lora_A', 'mask_decoder.output_hypernetworks_mlps.1.layers.1.parametrizations.weight.0.lora_B', 'mask_decoder.output_hypernetworks_mlps.1.layers.2.parametrizations.weight.0.lora_A', 'mask_decoder.output_hypernetworks_mlps.1.layers.2.parametrizations.weight.0.lora_B', 'mask_decoder.output_hypernetworks_mlps.2.layers.0.parametrizations.weight.0.lora_A', 'mask_decoder.output_hypernetworks_mlps.2.layers.0.parametrizations.weight.0.lora_B', 'mask_decoder.output_hypernetworks_mlps.2.layers.1.parametrizations.weight.0.lora_A', 'mask_decoder.output_hypernetworks_mlps.2.layers.1.parametrizations.weight.0.lora_B', 'mask_decoder.output_hypernetworks_mlps.2.layers.2.parametrizations.weight.0.lora_A', 'mask_decoder.output_hypernetworks_mlps.2.layers.2.parametrizations.weight.0.lora_B', 'mask_decoder.output_hypernetworks_mlps.3.layers.0.parametrizations.weight.0.lora_A', 'mask_decoder.output_hypernetworks_mlps.3.layers.0.parametrizations.weight.0.lora_B', 'mask_decoder.output_hypernetworks_mlps.3.layers.1.parametrizations.weight.0.lora_A', 'mask_decoder.output_hypernetworks_mlps.3.layers.1.parametrizations.weight.0.lora_B', 'mask_decoder.output_hypernetworks_mlps.3.layers.2.parametrizations.weight.0.lora_A', 'mask_decoder.output_hypernetworks_mlps.3.layers.2.parametrizations.weight.0.lora_B', 'mask_decoder.iou_prediction_head.layers.0.parametrizations.weight.0.lora_A', 'mask_decoder.iou_prediction_head.layers.0.parametrizations.weight.0.lora_B', 'mask_decoder.iou_prediction_head.layers.1.parametrizations.weight.0.lora_A', 'mask_decoder.iou_prediction_head.layers.1.parametrizations.weight.0.lora_B', 'mask_decoder.iou_prediction_head.layers.2.parametrizations.weight.0.lora_A', 'mask_decoder.iou_prediction_head.layers.2.parametrizations.weight.0.lora_B'])\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Add LoRA to the model\n",
    "add_lora(student.model.mask_decoder)\n",
    "\n",
    "# Step 2: Collect the parameters, pass them to the optimizer\n",
    "parameters = [{\"params\": list(get_lora_params(student.model.mask_decoder))}]\n",
    "optimizer = torch.optim.AdamW(parameters, lr=1e-3)\n",
    "\n",
    "# Step 3: Train the model\n",
    "# ...\n",
    "\n",
    "# Step 4: export the LoRA parameters\n",
    "lora_state_dict = get_lora_state_dict(model)\n",
    "print(lora_state_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94 110096\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in lora_state_dict.keys():\n",
    "    if 'decoder' in i:\n",
    "        # print(i, lora_state_dict[i].shape[0] * lora_state_dict[i].shape[1])\n",
    "        sum += lora_state_dict[i].shape[0] * lora_state_dict[i].shape[1]\n",
    "print(len(lora_state_dict), sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "transformer\n",
      "transformer.layers\n",
      "transformer.layers.0\n",
      "transformer.layers.0.self_attn\n",
      "transformer.layers.0.self_attn.q_proj\n",
      "transformer.layers.0.self_attn.q_proj.parametrizations\n",
      "transformer.layers.0.self_attn.q_proj.parametrizations.weight\n",
      "transformer.layers.0.self_attn.q_proj.parametrizations.weight.0\n",
      "transformer.layers.0.self_attn.k_proj\n",
      "transformer.layers.0.self_attn.k_proj.parametrizations\n",
      "transformer.layers.0.self_attn.k_proj.parametrizations.weight\n",
      "transformer.layers.0.self_attn.k_proj.parametrizations.weight.0\n",
      "transformer.layers.0.self_attn.v_proj\n",
      "transformer.layers.0.self_attn.v_proj.parametrizations\n",
      "transformer.layers.0.self_attn.v_proj.parametrizations.weight\n",
      "transformer.layers.0.self_attn.v_proj.parametrizations.weight.0\n",
      "transformer.layers.0.self_attn.out_proj\n",
      "transformer.layers.0.self_attn.out_proj.parametrizations\n",
      "transformer.layers.0.self_attn.out_proj.parametrizations.weight\n",
      "transformer.layers.0.self_attn.out_proj.parametrizations.weight.0\n",
      "transformer.layers.0.norm1\n",
      "transformer.layers.0.cross_attn_token_to_image\n",
      "transformer.layers.0.cross_attn_token_to_image.q_proj\n",
      "transformer.layers.0.cross_attn_token_to_image.q_proj.parametrizations\n",
      "transformer.layers.0.cross_attn_token_to_image.q_proj.parametrizations.weight\n",
      "transformer.layers.0.cross_attn_token_to_image.q_proj.parametrizations.weight.0\n",
      "transformer.layers.0.cross_attn_token_to_image.k_proj\n",
      "transformer.layers.0.cross_attn_token_to_image.k_proj.parametrizations\n",
      "transformer.layers.0.cross_attn_token_to_image.k_proj.parametrizations.weight\n",
      "transformer.layers.0.cross_attn_token_to_image.k_proj.parametrizations.weight.0\n",
      "transformer.layers.0.cross_attn_token_to_image.v_proj\n",
      "transformer.layers.0.cross_attn_token_to_image.v_proj.parametrizations\n",
      "transformer.layers.0.cross_attn_token_to_image.v_proj.parametrizations.weight\n",
      "transformer.layers.0.cross_attn_token_to_image.v_proj.parametrizations.weight.0\n",
      "transformer.layers.0.cross_attn_token_to_image.out_proj\n",
      "transformer.layers.0.cross_attn_token_to_image.out_proj.parametrizations\n",
      "transformer.layers.0.cross_attn_token_to_image.out_proj.parametrizations.weight\n",
      "transformer.layers.0.cross_attn_token_to_image.out_proj.parametrizations.weight.0\n",
      "transformer.layers.0.norm2\n",
      "transformer.layers.0.mlp\n",
      "transformer.layers.0.mlp.lin1\n",
      "transformer.layers.0.mlp.lin1.parametrizations\n",
      "transformer.layers.0.mlp.lin1.parametrizations.weight\n",
      "transformer.layers.0.mlp.lin1.parametrizations.weight.0\n",
      "transformer.layers.0.mlp.lin2\n",
      "transformer.layers.0.mlp.lin2.parametrizations\n",
      "transformer.layers.0.mlp.lin2.parametrizations.weight\n",
      "transformer.layers.0.mlp.lin2.parametrizations.weight.0\n",
      "transformer.layers.0.mlp.act\n",
      "transformer.layers.0.norm3\n",
      "transformer.layers.0.norm4\n",
      "transformer.layers.0.cross_attn_image_to_token\n",
      "transformer.layers.0.cross_attn_image_to_token.q_proj\n",
      "transformer.layers.0.cross_attn_image_to_token.q_proj.parametrizations\n",
      "transformer.layers.0.cross_attn_image_to_token.q_proj.parametrizations.weight\n",
      "transformer.layers.0.cross_attn_image_to_token.q_proj.parametrizations.weight.0\n",
      "transformer.layers.0.cross_attn_image_to_token.k_proj\n",
      "transformer.layers.0.cross_attn_image_to_token.k_proj.parametrizations\n",
      "transformer.layers.0.cross_attn_image_to_token.k_proj.parametrizations.weight\n",
      "transformer.layers.0.cross_attn_image_to_token.k_proj.parametrizations.weight.0\n",
      "transformer.layers.0.cross_attn_image_to_token.v_proj\n",
      "transformer.layers.0.cross_attn_image_to_token.v_proj.parametrizations\n",
      "transformer.layers.0.cross_attn_image_to_token.v_proj.parametrizations.weight\n",
      "transformer.layers.0.cross_attn_image_to_token.v_proj.parametrizations.weight.0\n",
      "transformer.layers.0.cross_attn_image_to_token.out_proj\n",
      "transformer.layers.0.cross_attn_image_to_token.out_proj.parametrizations\n",
      "transformer.layers.0.cross_attn_image_to_token.out_proj.parametrizations.weight\n",
      "transformer.layers.0.cross_attn_image_to_token.out_proj.parametrizations.weight.0\n",
      "transformer.layers.1\n",
      "transformer.layers.1.self_attn\n",
      "transformer.layers.1.self_attn.q_proj\n",
      "transformer.layers.1.self_attn.q_proj.parametrizations\n",
      "transformer.layers.1.self_attn.q_proj.parametrizations.weight\n",
      "transformer.layers.1.self_attn.q_proj.parametrizations.weight.0\n",
      "transformer.layers.1.self_attn.k_proj\n",
      "transformer.layers.1.self_attn.k_proj.parametrizations\n",
      "transformer.layers.1.self_attn.k_proj.parametrizations.weight\n",
      "transformer.layers.1.self_attn.k_proj.parametrizations.weight.0\n",
      "transformer.layers.1.self_attn.v_proj\n",
      "transformer.layers.1.self_attn.v_proj.parametrizations\n",
      "transformer.layers.1.self_attn.v_proj.parametrizations.weight\n",
      "transformer.layers.1.self_attn.v_proj.parametrizations.weight.0\n",
      "transformer.layers.1.self_attn.out_proj\n",
      "transformer.layers.1.self_attn.out_proj.parametrizations\n",
      "transformer.layers.1.self_attn.out_proj.parametrizations.weight\n",
      "transformer.layers.1.self_attn.out_proj.parametrizations.weight.0\n",
      "transformer.layers.1.norm1\n",
      "transformer.layers.1.cross_attn_token_to_image\n",
      "transformer.layers.1.cross_attn_token_to_image.q_proj\n",
      "transformer.layers.1.cross_attn_token_to_image.q_proj.parametrizations\n",
      "transformer.layers.1.cross_attn_token_to_image.q_proj.parametrizations.weight\n",
      "transformer.layers.1.cross_attn_token_to_image.q_proj.parametrizations.weight.0\n",
      "transformer.layers.1.cross_attn_token_to_image.k_proj\n",
      "transformer.layers.1.cross_attn_token_to_image.k_proj.parametrizations\n",
      "transformer.layers.1.cross_attn_token_to_image.k_proj.parametrizations.weight\n",
      "transformer.layers.1.cross_attn_token_to_image.k_proj.parametrizations.weight.0\n",
      "transformer.layers.1.cross_attn_token_to_image.v_proj\n",
      "transformer.layers.1.cross_attn_token_to_image.v_proj.parametrizations\n",
      "transformer.layers.1.cross_attn_token_to_image.v_proj.parametrizations.weight\n",
      "transformer.layers.1.cross_attn_token_to_image.v_proj.parametrizations.weight.0\n",
      "transformer.layers.1.cross_attn_token_to_image.out_proj\n",
      "transformer.layers.1.cross_attn_token_to_image.out_proj.parametrizations\n",
      "transformer.layers.1.cross_attn_token_to_image.out_proj.parametrizations.weight\n",
      "transformer.layers.1.cross_attn_token_to_image.out_proj.parametrizations.weight.0\n",
      "transformer.layers.1.norm2\n",
      "transformer.layers.1.mlp\n",
      "transformer.layers.1.mlp.lin1\n",
      "transformer.layers.1.mlp.lin1.parametrizations\n",
      "transformer.layers.1.mlp.lin1.parametrizations.weight\n",
      "transformer.layers.1.mlp.lin1.parametrizations.weight.0\n",
      "transformer.layers.1.mlp.lin2\n",
      "transformer.layers.1.mlp.lin2.parametrizations\n",
      "transformer.layers.1.mlp.lin2.parametrizations.weight\n",
      "transformer.layers.1.mlp.lin2.parametrizations.weight.0\n",
      "transformer.layers.1.mlp.act\n",
      "transformer.layers.1.norm3\n",
      "transformer.layers.1.norm4\n",
      "transformer.layers.1.cross_attn_image_to_token\n",
      "transformer.layers.1.cross_attn_image_to_token.q_proj\n",
      "transformer.layers.1.cross_attn_image_to_token.q_proj.parametrizations\n",
      "transformer.layers.1.cross_attn_image_to_token.q_proj.parametrizations.weight\n",
      "transformer.layers.1.cross_attn_image_to_token.q_proj.parametrizations.weight.0\n",
      "transformer.layers.1.cross_attn_image_to_token.k_proj\n",
      "transformer.layers.1.cross_attn_image_to_token.k_proj.parametrizations\n",
      "transformer.layers.1.cross_attn_image_to_token.k_proj.parametrizations.weight\n",
      "transformer.layers.1.cross_attn_image_to_token.k_proj.parametrizations.weight.0\n",
      "transformer.layers.1.cross_attn_image_to_token.v_proj\n",
      "transformer.layers.1.cross_attn_image_to_token.v_proj.parametrizations\n",
      "transformer.layers.1.cross_attn_image_to_token.v_proj.parametrizations.weight\n",
      "transformer.layers.1.cross_attn_image_to_token.v_proj.parametrizations.weight.0\n",
      "transformer.layers.1.cross_attn_image_to_token.out_proj\n",
      "transformer.layers.1.cross_attn_image_to_token.out_proj.parametrizations\n",
      "transformer.layers.1.cross_attn_image_to_token.out_proj.parametrizations.weight\n",
      "transformer.layers.1.cross_attn_image_to_token.out_proj.parametrizations.weight.0\n",
      "transformer.final_attn_token_to_image\n",
      "transformer.final_attn_token_to_image.q_proj\n",
      "transformer.final_attn_token_to_image.q_proj.parametrizations\n",
      "transformer.final_attn_token_to_image.q_proj.parametrizations.weight\n",
      "transformer.final_attn_token_to_image.q_proj.parametrizations.weight.0\n",
      "transformer.final_attn_token_to_image.k_proj\n",
      "transformer.final_attn_token_to_image.k_proj.parametrizations\n",
      "transformer.final_attn_token_to_image.k_proj.parametrizations.weight\n",
      "transformer.final_attn_token_to_image.k_proj.parametrizations.weight.0\n",
      "transformer.final_attn_token_to_image.v_proj\n",
      "transformer.final_attn_token_to_image.v_proj.parametrizations\n",
      "transformer.final_attn_token_to_image.v_proj.parametrizations.weight\n",
      "transformer.final_attn_token_to_image.v_proj.parametrizations.weight.0\n",
      "transformer.final_attn_token_to_image.out_proj\n",
      "transformer.final_attn_token_to_image.out_proj.parametrizations\n",
      "transformer.final_attn_token_to_image.out_proj.parametrizations.weight\n",
      "transformer.final_attn_token_to_image.out_proj.parametrizations.weight.0\n",
      "transformer.norm_final_attn\n",
      "iou_token\n",
      "mask_tokens\n",
      "output_upscaling\n",
      "output_upscaling.0\n",
      "output_upscaling.1\n",
      "output_upscaling.2\n",
      "output_upscaling.3\n",
      "output_upscaling.4\n",
      "output_hypernetworks_mlps\n",
      "output_hypernetworks_mlps.0\n",
      "output_hypernetworks_mlps.0.layers\n",
      "output_hypernetworks_mlps.0.layers.0\n",
      "output_hypernetworks_mlps.0.layers.0.parametrizations\n",
      "output_hypernetworks_mlps.0.layers.0.parametrizations.weight\n",
      "output_hypernetworks_mlps.0.layers.0.parametrizations.weight.0\n",
      "output_hypernetworks_mlps.0.layers.1\n",
      "output_hypernetworks_mlps.0.layers.1.parametrizations\n",
      "output_hypernetworks_mlps.0.layers.1.parametrizations.weight\n",
      "output_hypernetworks_mlps.0.layers.1.parametrizations.weight.0\n",
      "output_hypernetworks_mlps.0.layers.2\n",
      "output_hypernetworks_mlps.0.layers.2.parametrizations\n",
      "output_hypernetworks_mlps.0.layers.2.parametrizations.weight\n",
      "output_hypernetworks_mlps.0.layers.2.parametrizations.weight.0\n",
      "output_hypernetworks_mlps.1\n",
      "output_hypernetworks_mlps.1.layers\n",
      "output_hypernetworks_mlps.1.layers.0\n",
      "output_hypernetworks_mlps.1.layers.0.parametrizations\n",
      "output_hypernetworks_mlps.1.layers.0.parametrizations.weight\n",
      "output_hypernetworks_mlps.1.layers.0.parametrizations.weight.0\n",
      "output_hypernetworks_mlps.1.layers.1\n",
      "output_hypernetworks_mlps.1.layers.1.parametrizations\n",
      "output_hypernetworks_mlps.1.layers.1.parametrizations.weight\n",
      "output_hypernetworks_mlps.1.layers.1.parametrizations.weight.0\n",
      "output_hypernetworks_mlps.1.layers.2\n",
      "output_hypernetworks_mlps.1.layers.2.parametrizations\n",
      "output_hypernetworks_mlps.1.layers.2.parametrizations.weight\n",
      "output_hypernetworks_mlps.1.layers.2.parametrizations.weight.0\n",
      "output_hypernetworks_mlps.2\n",
      "output_hypernetworks_mlps.2.layers\n",
      "output_hypernetworks_mlps.2.layers.0\n",
      "output_hypernetworks_mlps.2.layers.0.parametrizations\n",
      "output_hypernetworks_mlps.2.layers.0.parametrizations.weight\n",
      "output_hypernetworks_mlps.2.layers.0.parametrizations.weight.0\n",
      "output_hypernetworks_mlps.2.layers.1\n",
      "output_hypernetworks_mlps.2.layers.1.parametrizations\n",
      "output_hypernetworks_mlps.2.layers.1.parametrizations.weight\n",
      "output_hypernetworks_mlps.2.layers.1.parametrizations.weight.0\n",
      "output_hypernetworks_mlps.2.layers.2\n",
      "output_hypernetworks_mlps.2.layers.2.parametrizations\n",
      "output_hypernetworks_mlps.2.layers.2.parametrizations.weight\n",
      "output_hypernetworks_mlps.2.layers.2.parametrizations.weight.0\n",
      "output_hypernetworks_mlps.3\n",
      "output_hypernetworks_mlps.3.layers\n",
      "output_hypernetworks_mlps.3.layers.0\n",
      "output_hypernetworks_mlps.3.layers.0.parametrizations\n",
      "output_hypernetworks_mlps.3.layers.0.parametrizations.weight\n",
      "output_hypernetworks_mlps.3.layers.0.parametrizations.weight.0\n",
      "output_hypernetworks_mlps.3.layers.1\n",
      "output_hypernetworks_mlps.3.layers.1.parametrizations\n",
      "output_hypernetworks_mlps.3.layers.1.parametrizations.weight\n",
      "output_hypernetworks_mlps.3.layers.1.parametrizations.weight.0\n",
      "output_hypernetworks_mlps.3.layers.2\n",
      "output_hypernetworks_mlps.3.layers.2.parametrizations\n",
      "output_hypernetworks_mlps.3.layers.2.parametrizations.weight\n",
      "output_hypernetworks_mlps.3.layers.2.parametrizations.weight.0\n",
      "iou_prediction_head\n",
      "iou_prediction_head.layers\n",
      "iou_prediction_head.layers.0\n",
      "iou_prediction_head.layers.0.parametrizations\n",
      "iou_prediction_head.layers.0.parametrizations.weight\n",
      "iou_prediction_head.layers.0.parametrizations.weight.0\n",
      "iou_prediction_head.layers.1\n",
      "iou_prediction_head.layers.1.parametrizations\n",
      "iou_prediction_head.layers.1.parametrizations.weight\n",
      "iou_prediction_head.layers.1.parametrizations.weight.0\n",
      "iou_prediction_head.layers.2\n",
      "iou_prediction_head.layers.2.parametrizations\n",
      "iou_prediction_head.layers.2.parametrizations.weight\n",
      "iou_prediction_head.layers.2.parametrizations.weight.0\n"
     ]
    }
   ],
   "source": [
    "for n, m in student.model.mask_decoder.named_modules():\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "transformer\n",
      "transformer.layers\n",
      "transformer.layers.0\n",
      "transformer.layers.0.self_attn\n",
      "transformer.layers.0.self_attn.q_proj\n",
      "transformer.layers.0.self_attn.k_proj\n",
      "transformer.layers.0.self_attn.v_proj\n",
      "transformer.layers.0.self_attn.out_proj\n",
      "transformer.layers.0.norm1\n",
      "transformer.layers.0.cross_attn_token_to_image\n",
      "transformer.layers.0.cross_attn_token_to_image.q_proj\n",
      "transformer.layers.0.cross_attn_token_to_image.k_proj\n",
      "transformer.layers.0.cross_attn_token_to_image.v_proj\n",
      "transformer.layers.0.cross_attn_token_to_image.out_proj\n",
      "transformer.layers.0.norm2\n",
      "transformer.layers.0.mlp\n",
      "transformer.layers.0.mlp.lin1\n",
      "transformer.layers.0.mlp.lin2\n",
      "transformer.layers.0.mlp.act\n",
      "transformer.layers.0.norm3\n",
      "transformer.layers.0.norm4\n",
      "transformer.layers.0.cross_attn_image_to_token\n",
      "transformer.layers.0.cross_attn_image_to_token.q_proj\n",
      "transformer.layers.0.cross_attn_image_to_token.k_proj\n",
      "transformer.layers.0.cross_attn_image_to_token.v_proj\n",
      "transformer.layers.0.cross_attn_image_to_token.out_proj\n",
      "transformer.layers.1\n",
      "transformer.layers.1.self_attn\n",
      "transformer.layers.1.self_attn.q_proj\n",
      "transformer.layers.1.self_attn.k_proj\n",
      "transformer.layers.1.self_attn.v_proj\n",
      "transformer.layers.1.self_attn.out_proj\n",
      "transformer.layers.1.norm1\n",
      "transformer.layers.1.cross_attn_token_to_image\n",
      "transformer.layers.1.cross_attn_token_to_image.q_proj\n",
      "transformer.layers.1.cross_attn_token_to_image.k_proj\n",
      "transformer.layers.1.cross_attn_token_to_image.v_proj\n",
      "transformer.layers.1.cross_attn_token_to_image.out_proj\n",
      "transformer.layers.1.norm2\n",
      "transformer.layers.1.mlp\n",
      "transformer.layers.1.mlp.lin1\n",
      "transformer.layers.1.mlp.lin2\n",
      "transformer.layers.1.mlp.act\n",
      "transformer.layers.1.norm3\n",
      "transformer.layers.1.norm4\n",
      "transformer.layers.1.cross_attn_image_to_token\n",
      "transformer.layers.1.cross_attn_image_to_token.q_proj\n",
      "transformer.layers.1.cross_attn_image_to_token.k_proj\n",
      "transformer.layers.1.cross_attn_image_to_token.v_proj\n",
      "transformer.layers.1.cross_attn_image_to_token.out_proj\n",
      "transformer.final_attn_token_to_image\n",
      "transformer.final_attn_token_to_image.q_proj\n",
      "transformer.final_attn_token_to_image.k_proj\n",
      "transformer.final_attn_token_to_image.v_proj\n",
      "transformer.final_attn_token_to_image.out_proj\n",
      "transformer.norm_final_attn\n",
      "iou_token\n",
      "mask_tokens\n",
      "output_upscaling\n",
      "output_upscaling.0\n",
      "output_upscaling.1\n",
      "output_upscaling.2\n",
      "output_upscaling.3\n",
      "output_upscaling.4\n",
      "output_hypernetworks_mlps\n",
      "output_hypernetworks_mlps.0\n",
      "output_hypernetworks_mlps.0.layers\n",
      "output_hypernetworks_mlps.0.layers.0\n",
      "output_hypernetworks_mlps.0.layers.1\n",
      "output_hypernetworks_mlps.0.layers.2\n",
      "output_hypernetworks_mlps.1\n",
      "output_hypernetworks_mlps.1.layers\n",
      "output_hypernetworks_mlps.1.layers.0\n",
      "output_hypernetworks_mlps.1.layers.1\n",
      "output_hypernetworks_mlps.1.layers.2\n",
      "output_hypernetworks_mlps.2\n",
      "output_hypernetworks_mlps.2.layers\n",
      "output_hypernetworks_mlps.2.layers.0\n",
      "output_hypernetworks_mlps.2.layers.1\n",
      "output_hypernetworks_mlps.2.layers.2\n",
      "output_hypernetworks_mlps.3\n",
      "output_hypernetworks_mlps.3.layers\n",
      "output_hypernetworks_mlps.3.layers.0\n",
      "output_hypernetworks_mlps.3.layers.1\n",
      "output_hypernetworks_mlps.3.layers.2\n",
      "iou_prediction_head\n",
      "iou_prediction_head.layers\n",
      "iou_prediction_head.layers.0\n",
      "iou_prediction_head.layers.1\n",
      "iou_prediction_head.layers.2\n"
     ]
    }
   ],
   "source": [
    "for n, m in student.model.mask_decoder.named_modules():\n",
    "    if 'parametrization' in n:\n",
    "        m.train()\n",
    "        #print(n)\n",
    "    else:\n",
    "        m.eval()\n",
    "        print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "o = torch.load('../test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.load('merged.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_decoder.transformer.layers.0.self_attn.q_proj.weight False\n",
      "mask_decoder.transformer.layers.0.self_attn.k_proj.weight False\n",
      "mask_decoder.transformer.layers.0.self_attn.v_proj.weight False\n",
      "mask_decoder.transformer.layers.0.self_attn.out_proj.weight False\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.weight False\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.weight False\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.weight False\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.weight False\n",
      "mask_decoder.transformer.layers.0.mlp.lin1.weight False\n",
      "mask_decoder.transformer.layers.0.mlp.lin2.weight False\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.weight False\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.weight False\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.weight False\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.weight False\n",
      "mask_decoder.transformer.layers.1.self_attn.q_proj.weight False\n",
      "mask_decoder.transformer.layers.1.self_attn.k_proj.weight False\n",
      "mask_decoder.transformer.layers.1.self_attn.v_proj.weight False\n",
      "mask_decoder.transformer.layers.1.self_attn.out_proj.weight False\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.weight False\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.weight False\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.weight False\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.weight False\n",
      "mask_decoder.transformer.layers.1.mlp.lin1.weight False\n",
      "mask_decoder.transformer.layers.1.mlp.lin2.weight False\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.weight False\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.weight False\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.weight False\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.weight False\n",
      "mask_decoder.transformer.final_attn_token_to_image.q_proj.weight False\n",
      "mask_decoder.transformer.final_attn_token_to_image.k_proj.weight False\n",
      "mask_decoder.transformer.final_attn_token_to_image.v_proj.weight False\n",
      "mask_decoder.transformer.final_attn_token_to_image.out_proj.weight False\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.0.weight False\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.1.weight False\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.2.weight False\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.0.weight False\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.1.weight False\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.2.weight False\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.0.weight False\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.1.weight False\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.2.weight False\n",
      "3694592\n"
     ]
    }
   ],
   "source": [
    "sum = 0\n",
    "for i in o.keys():\n",
    "    test = bool((o[i].cpu() == l[i].cpu()).all())\n",
    "    if not test:\n",
    "        print(i, test)\n",
    "        sum += o[i].shape[0] * o[i].shape[1]\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_encoder.patch_embed.seq.0.c.weight\n",
      "image_encoder.patch_embed.seq.0.bn.weight\n",
      "image_encoder.patch_embed.seq.0.bn.bias\n",
      "image_encoder.patch_embed.seq.0.bn.running_mean\n",
      "image_encoder.patch_embed.seq.0.bn.running_var\n",
      "image_encoder.patch_embed.seq.0.bn.num_batches_tracked\n",
      "image_encoder.patch_embed.seq.2.c.weight\n",
      "image_encoder.patch_embed.seq.2.bn.weight\n",
      "image_encoder.patch_embed.seq.2.bn.bias\n",
      "image_encoder.patch_embed.seq.2.bn.running_mean\n",
      "image_encoder.patch_embed.seq.2.bn.running_var\n",
      "image_encoder.patch_embed.seq.2.bn.num_batches_tracked\n",
      "image_encoder.layers.0.blocks.0.conv1.c.weight\n",
      "image_encoder.layers.0.blocks.0.conv1.bn.weight\n",
      "image_encoder.layers.0.blocks.0.conv1.bn.bias\n",
      "image_encoder.layers.0.blocks.0.conv1.bn.running_mean\n",
      "image_encoder.layers.0.blocks.0.conv1.bn.running_var\n",
      "image_encoder.layers.0.blocks.0.conv1.bn.num_batches_tracked\n",
      "image_encoder.layers.0.blocks.0.conv2.c.weight\n",
      "image_encoder.layers.0.blocks.0.conv2.bn.weight\n",
      "image_encoder.layers.0.blocks.0.conv2.bn.bias\n",
      "image_encoder.layers.0.blocks.0.conv2.bn.running_mean\n",
      "image_encoder.layers.0.blocks.0.conv2.bn.running_var\n",
      "image_encoder.layers.0.blocks.0.conv2.bn.num_batches_tracked\n",
      "image_encoder.layers.0.blocks.0.conv3.c.weight\n",
      "image_encoder.layers.0.blocks.0.conv3.bn.weight\n",
      "image_encoder.layers.0.blocks.0.conv3.bn.bias\n",
      "image_encoder.layers.0.blocks.0.conv3.bn.running_mean\n",
      "image_encoder.layers.0.blocks.0.conv3.bn.running_var\n",
      "image_encoder.layers.0.blocks.0.conv3.bn.num_batches_tracked\n",
      "image_encoder.layers.0.blocks.1.conv1.c.weight\n",
      "image_encoder.layers.0.blocks.1.conv1.bn.weight\n",
      "image_encoder.layers.0.blocks.1.conv1.bn.bias\n",
      "image_encoder.layers.0.blocks.1.conv1.bn.running_mean\n",
      "image_encoder.layers.0.blocks.1.conv1.bn.running_var\n",
      "image_encoder.layers.0.blocks.1.conv1.bn.num_batches_tracked\n",
      "image_encoder.layers.0.blocks.1.conv2.c.weight\n",
      "image_encoder.layers.0.blocks.1.conv2.bn.weight\n",
      "image_encoder.layers.0.blocks.1.conv2.bn.bias\n",
      "image_encoder.layers.0.blocks.1.conv2.bn.running_mean\n",
      "image_encoder.layers.0.blocks.1.conv2.bn.running_var\n",
      "image_encoder.layers.0.blocks.1.conv2.bn.num_batches_tracked\n",
      "image_encoder.layers.0.blocks.1.conv3.c.weight\n",
      "image_encoder.layers.0.blocks.1.conv3.bn.weight\n",
      "image_encoder.layers.0.blocks.1.conv3.bn.bias\n",
      "image_encoder.layers.0.blocks.1.conv3.bn.running_mean\n",
      "image_encoder.layers.0.blocks.1.conv3.bn.running_var\n",
      "image_encoder.layers.0.blocks.1.conv3.bn.num_batches_tracked\n",
      "image_encoder.layers.0.downsample.conv1.c.weight\n",
      "image_encoder.layers.0.downsample.conv1.bn.weight\n",
      "image_encoder.layers.0.downsample.conv1.bn.bias\n",
      "image_encoder.layers.0.downsample.conv1.bn.running_mean\n",
      "image_encoder.layers.0.downsample.conv1.bn.running_var\n",
      "image_encoder.layers.0.downsample.conv1.bn.num_batches_tracked\n",
      "image_encoder.layers.0.downsample.conv2.c.weight\n",
      "image_encoder.layers.0.downsample.conv2.bn.weight\n",
      "image_encoder.layers.0.downsample.conv2.bn.bias\n",
      "image_encoder.layers.0.downsample.conv2.bn.running_mean\n",
      "image_encoder.layers.0.downsample.conv2.bn.running_var\n",
      "image_encoder.layers.0.downsample.conv2.bn.num_batches_tracked\n",
      "image_encoder.layers.0.downsample.conv3.c.weight\n",
      "image_encoder.layers.0.downsample.conv3.bn.weight\n",
      "image_encoder.layers.0.downsample.conv3.bn.bias\n",
      "image_encoder.layers.0.downsample.conv3.bn.running_mean\n",
      "image_encoder.layers.0.downsample.conv3.bn.running_var\n",
      "image_encoder.layers.0.downsample.conv3.bn.num_batches_tracked\n",
      "image_encoder.layers.1.blocks.0.attn.attention_biases\n",
      "image_encoder.layers.1.blocks.0.attn.norm.weight\n",
      "image_encoder.layers.1.blocks.0.attn.norm.bias\n",
      "image_encoder.layers.1.blocks.0.attn.qkv.weight\n",
      "image_encoder.layers.1.blocks.0.attn.qkv.bias\n",
      "image_encoder.layers.1.blocks.0.attn.proj.weight\n",
      "image_encoder.layers.1.blocks.0.attn.proj.bias\n",
      "image_encoder.layers.1.blocks.0.mlp.norm.weight\n",
      "image_encoder.layers.1.blocks.0.mlp.norm.bias\n",
      "image_encoder.layers.1.blocks.0.mlp.fc1.weight\n",
      "image_encoder.layers.1.blocks.0.mlp.fc1.bias\n",
      "image_encoder.layers.1.blocks.0.mlp.fc2.weight\n",
      "image_encoder.layers.1.blocks.0.mlp.fc2.bias\n",
      "image_encoder.layers.1.blocks.0.local_conv.c.weight\n",
      "image_encoder.layers.1.blocks.0.local_conv.bn.weight\n",
      "image_encoder.layers.1.blocks.0.local_conv.bn.bias\n",
      "image_encoder.layers.1.blocks.0.local_conv.bn.running_mean\n",
      "image_encoder.layers.1.blocks.0.local_conv.bn.running_var\n",
      "image_encoder.layers.1.blocks.0.local_conv.bn.num_batches_tracked\n",
      "image_encoder.layers.1.blocks.1.attn.attention_biases\n",
      "image_encoder.layers.1.blocks.1.attn.norm.weight\n",
      "image_encoder.layers.1.blocks.1.attn.norm.bias\n",
      "image_encoder.layers.1.blocks.1.attn.qkv.weight\n",
      "image_encoder.layers.1.blocks.1.attn.qkv.bias\n",
      "image_encoder.layers.1.blocks.1.attn.proj.weight\n",
      "image_encoder.layers.1.blocks.1.attn.proj.bias\n",
      "image_encoder.layers.1.blocks.1.mlp.norm.weight\n",
      "image_encoder.layers.1.blocks.1.mlp.norm.bias\n",
      "image_encoder.layers.1.blocks.1.mlp.fc1.weight\n",
      "image_encoder.layers.1.blocks.1.mlp.fc1.bias\n",
      "image_encoder.layers.1.blocks.1.mlp.fc2.weight\n",
      "image_encoder.layers.1.blocks.1.mlp.fc2.bias\n",
      "image_encoder.layers.1.blocks.1.local_conv.c.weight\n",
      "image_encoder.layers.1.blocks.1.local_conv.bn.weight\n",
      "image_encoder.layers.1.blocks.1.local_conv.bn.bias\n",
      "image_encoder.layers.1.blocks.1.local_conv.bn.running_mean\n",
      "image_encoder.layers.1.blocks.1.local_conv.bn.running_var\n",
      "image_encoder.layers.1.blocks.1.local_conv.bn.num_batches_tracked\n",
      "image_encoder.layers.1.downsample.conv1.c.weight\n",
      "image_encoder.layers.1.downsample.conv1.bn.weight\n",
      "image_encoder.layers.1.downsample.conv1.bn.bias\n",
      "image_encoder.layers.1.downsample.conv1.bn.running_mean\n",
      "image_encoder.layers.1.downsample.conv1.bn.running_var\n",
      "image_encoder.layers.1.downsample.conv1.bn.num_batches_tracked\n",
      "image_encoder.layers.1.downsample.conv2.c.weight\n",
      "image_encoder.layers.1.downsample.conv2.bn.weight\n",
      "image_encoder.layers.1.downsample.conv2.bn.bias\n",
      "image_encoder.layers.1.downsample.conv2.bn.running_mean\n",
      "image_encoder.layers.1.downsample.conv2.bn.running_var\n",
      "image_encoder.layers.1.downsample.conv2.bn.num_batches_tracked\n",
      "image_encoder.layers.1.downsample.conv3.c.weight\n",
      "image_encoder.layers.1.downsample.conv3.bn.weight\n",
      "image_encoder.layers.1.downsample.conv3.bn.bias\n",
      "image_encoder.layers.1.downsample.conv3.bn.running_mean\n",
      "image_encoder.layers.1.downsample.conv3.bn.running_var\n",
      "image_encoder.layers.1.downsample.conv3.bn.num_batches_tracked\n",
      "image_encoder.layers.2.blocks.0.attn.attention_biases\n",
      "image_encoder.layers.2.blocks.0.attn.norm.weight\n",
      "image_encoder.layers.2.blocks.0.attn.norm.bias\n",
      "image_encoder.layers.2.blocks.0.attn.qkv.weight\n",
      "image_encoder.layers.2.blocks.0.attn.qkv.bias\n",
      "image_encoder.layers.2.blocks.0.attn.proj.weight\n",
      "image_encoder.layers.2.blocks.0.attn.proj.bias\n",
      "image_encoder.layers.2.blocks.0.mlp.norm.weight\n",
      "image_encoder.layers.2.blocks.0.mlp.norm.bias\n",
      "image_encoder.layers.2.blocks.0.mlp.fc1.weight\n",
      "image_encoder.layers.2.blocks.0.mlp.fc1.bias\n",
      "image_encoder.layers.2.blocks.0.mlp.fc2.weight\n",
      "image_encoder.layers.2.blocks.0.mlp.fc2.bias\n",
      "image_encoder.layers.2.blocks.0.local_conv.c.weight\n",
      "image_encoder.layers.2.blocks.0.local_conv.bn.weight\n",
      "image_encoder.layers.2.blocks.0.local_conv.bn.bias\n",
      "image_encoder.layers.2.blocks.0.local_conv.bn.running_mean\n",
      "image_encoder.layers.2.blocks.0.local_conv.bn.running_var\n",
      "image_encoder.layers.2.blocks.0.local_conv.bn.num_batches_tracked\n",
      "image_encoder.layers.2.blocks.1.attn.attention_biases\n",
      "image_encoder.layers.2.blocks.1.attn.norm.weight\n",
      "image_encoder.layers.2.blocks.1.attn.norm.bias\n",
      "image_encoder.layers.2.blocks.1.attn.qkv.weight\n",
      "image_encoder.layers.2.blocks.1.attn.qkv.bias\n",
      "image_encoder.layers.2.blocks.1.attn.proj.weight\n",
      "image_encoder.layers.2.blocks.1.attn.proj.bias\n",
      "image_encoder.layers.2.blocks.1.mlp.norm.weight\n",
      "image_encoder.layers.2.blocks.1.mlp.norm.bias\n",
      "image_encoder.layers.2.blocks.1.mlp.fc1.weight\n",
      "image_encoder.layers.2.blocks.1.mlp.fc1.bias\n",
      "image_encoder.layers.2.blocks.1.mlp.fc2.weight\n",
      "image_encoder.layers.2.blocks.1.mlp.fc2.bias\n",
      "image_encoder.layers.2.blocks.1.local_conv.c.weight\n",
      "image_encoder.layers.2.blocks.1.local_conv.bn.weight\n",
      "image_encoder.layers.2.blocks.1.local_conv.bn.bias\n",
      "image_encoder.layers.2.blocks.1.local_conv.bn.running_mean\n",
      "image_encoder.layers.2.blocks.1.local_conv.bn.running_var\n",
      "image_encoder.layers.2.blocks.1.local_conv.bn.num_batches_tracked\n",
      "image_encoder.layers.2.blocks.2.attn.attention_biases\n",
      "image_encoder.layers.2.blocks.2.attn.norm.weight\n",
      "image_encoder.layers.2.blocks.2.attn.norm.bias\n",
      "image_encoder.layers.2.blocks.2.attn.qkv.weight\n",
      "image_encoder.layers.2.blocks.2.attn.qkv.bias\n",
      "image_encoder.layers.2.blocks.2.attn.proj.weight\n",
      "image_encoder.layers.2.blocks.2.attn.proj.bias\n",
      "image_encoder.layers.2.blocks.2.mlp.norm.weight\n",
      "image_encoder.layers.2.blocks.2.mlp.norm.bias\n",
      "image_encoder.layers.2.blocks.2.mlp.fc1.weight\n",
      "image_encoder.layers.2.blocks.2.mlp.fc1.bias\n",
      "image_encoder.layers.2.blocks.2.mlp.fc2.weight\n",
      "image_encoder.layers.2.blocks.2.mlp.fc2.bias\n",
      "image_encoder.layers.2.blocks.2.local_conv.c.weight\n",
      "image_encoder.layers.2.blocks.2.local_conv.bn.weight\n",
      "image_encoder.layers.2.blocks.2.local_conv.bn.bias\n",
      "image_encoder.layers.2.blocks.2.local_conv.bn.running_mean\n",
      "image_encoder.layers.2.blocks.2.local_conv.bn.running_var\n",
      "image_encoder.layers.2.blocks.2.local_conv.bn.num_batches_tracked\n",
      "image_encoder.layers.2.blocks.3.attn.attention_biases\n",
      "image_encoder.layers.2.blocks.3.attn.norm.weight\n",
      "image_encoder.layers.2.blocks.3.attn.norm.bias\n",
      "image_encoder.layers.2.blocks.3.attn.qkv.weight\n",
      "image_encoder.layers.2.blocks.3.attn.qkv.bias\n",
      "image_encoder.layers.2.blocks.3.attn.proj.weight\n",
      "image_encoder.layers.2.blocks.3.attn.proj.bias\n",
      "image_encoder.layers.2.blocks.3.mlp.norm.weight\n",
      "image_encoder.layers.2.blocks.3.mlp.norm.bias\n",
      "image_encoder.layers.2.blocks.3.mlp.fc1.weight\n",
      "image_encoder.layers.2.blocks.3.mlp.fc1.bias\n",
      "image_encoder.layers.2.blocks.3.mlp.fc2.weight\n",
      "image_encoder.layers.2.blocks.3.mlp.fc2.bias\n",
      "image_encoder.layers.2.blocks.3.local_conv.c.weight\n",
      "image_encoder.layers.2.blocks.3.local_conv.bn.weight\n",
      "image_encoder.layers.2.blocks.3.local_conv.bn.bias\n",
      "image_encoder.layers.2.blocks.3.local_conv.bn.running_mean\n",
      "image_encoder.layers.2.blocks.3.local_conv.bn.running_var\n",
      "image_encoder.layers.2.blocks.3.local_conv.bn.num_batches_tracked\n",
      "image_encoder.layers.2.blocks.4.attn.attention_biases\n",
      "image_encoder.layers.2.blocks.4.attn.norm.weight\n",
      "image_encoder.layers.2.blocks.4.attn.norm.bias\n",
      "image_encoder.layers.2.blocks.4.attn.qkv.weight\n",
      "image_encoder.layers.2.blocks.4.attn.qkv.bias\n",
      "image_encoder.layers.2.blocks.4.attn.proj.weight\n",
      "image_encoder.layers.2.blocks.4.attn.proj.bias\n",
      "image_encoder.layers.2.blocks.4.mlp.norm.weight\n",
      "image_encoder.layers.2.blocks.4.mlp.norm.bias\n",
      "image_encoder.layers.2.blocks.4.mlp.fc1.weight\n",
      "image_encoder.layers.2.blocks.4.mlp.fc1.bias\n",
      "image_encoder.layers.2.blocks.4.mlp.fc2.weight\n",
      "image_encoder.layers.2.blocks.4.mlp.fc2.bias\n",
      "image_encoder.layers.2.blocks.4.local_conv.c.weight\n",
      "image_encoder.layers.2.blocks.4.local_conv.bn.weight\n",
      "image_encoder.layers.2.blocks.4.local_conv.bn.bias\n",
      "image_encoder.layers.2.blocks.4.local_conv.bn.running_mean\n",
      "image_encoder.layers.2.blocks.4.local_conv.bn.running_var\n",
      "image_encoder.layers.2.blocks.4.local_conv.bn.num_batches_tracked\n",
      "image_encoder.layers.2.blocks.5.attn.attention_biases\n",
      "image_encoder.layers.2.blocks.5.attn.norm.weight\n",
      "image_encoder.layers.2.blocks.5.attn.norm.bias\n",
      "image_encoder.layers.2.blocks.5.attn.qkv.weight\n",
      "image_encoder.layers.2.blocks.5.attn.qkv.bias\n",
      "image_encoder.layers.2.blocks.5.attn.proj.weight\n",
      "image_encoder.layers.2.blocks.5.attn.proj.bias\n",
      "image_encoder.layers.2.blocks.5.mlp.norm.weight\n",
      "image_encoder.layers.2.blocks.5.mlp.norm.bias\n",
      "image_encoder.layers.2.blocks.5.mlp.fc1.weight\n",
      "image_encoder.layers.2.blocks.5.mlp.fc1.bias\n",
      "image_encoder.layers.2.blocks.5.mlp.fc2.weight\n",
      "image_encoder.layers.2.blocks.5.mlp.fc2.bias\n",
      "image_encoder.layers.2.blocks.5.local_conv.c.weight\n",
      "image_encoder.layers.2.blocks.5.local_conv.bn.weight\n",
      "image_encoder.layers.2.blocks.5.local_conv.bn.bias\n",
      "image_encoder.layers.2.blocks.5.local_conv.bn.running_mean\n",
      "image_encoder.layers.2.blocks.5.local_conv.bn.running_var\n",
      "image_encoder.layers.2.blocks.5.local_conv.bn.num_batches_tracked\n",
      "image_encoder.layers.2.downsample.conv1.c.weight\n",
      "image_encoder.layers.2.downsample.conv1.bn.weight\n",
      "image_encoder.layers.2.downsample.conv1.bn.bias\n",
      "image_encoder.layers.2.downsample.conv1.bn.running_mean\n",
      "image_encoder.layers.2.downsample.conv1.bn.running_var\n",
      "image_encoder.layers.2.downsample.conv1.bn.num_batches_tracked\n",
      "image_encoder.layers.2.downsample.conv2.c.weight\n",
      "image_encoder.layers.2.downsample.conv2.bn.weight\n",
      "image_encoder.layers.2.downsample.conv2.bn.bias\n",
      "image_encoder.layers.2.downsample.conv2.bn.running_mean\n",
      "image_encoder.layers.2.downsample.conv2.bn.running_var\n",
      "image_encoder.layers.2.downsample.conv2.bn.num_batches_tracked\n",
      "image_encoder.layers.2.downsample.conv3.c.weight\n",
      "image_encoder.layers.2.downsample.conv3.bn.weight\n",
      "image_encoder.layers.2.downsample.conv3.bn.bias\n",
      "image_encoder.layers.2.downsample.conv3.bn.running_mean\n",
      "image_encoder.layers.2.downsample.conv3.bn.running_var\n",
      "image_encoder.layers.2.downsample.conv3.bn.num_batches_tracked\n",
      "image_encoder.layers.3.blocks.0.attn.attention_biases\n",
      "image_encoder.layers.3.blocks.0.attn.norm.weight\n",
      "image_encoder.layers.3.blocks.0.attn.norm.bias\n",
      "image_encoder.layers.3.blocks.0.attn.qkv.weight\n",
      "image_encoder.layers.3.blocks.0.attn.qkv.bias\n",
      "image_encoder.layers.3.blocks.0.attn.proj.weight\n",
      "image_encoder.layers.3.blocks.0.attn.proj.bias\n",
      "image_encoder.layers.3.blocks.0.mlp.norm.weight\n",
      "image_encoder.layers.3.blocks.0.mlp.norm.bias\n",
      "image_encoder.layers.3.blocks.0.mlp.fc1.weight\n",
      "image_encoder.layers.3.blocks.0.mlp.fc1.bias\n",
      "image_encoder.layers.3.blocks.0.mlp.fc2.weight\n",
      "image_encoder.layers.3.blocks.0.mlp.fc2.bias\n",
      "image_encoder.layers.3.blocks.0.local_conv.c.weight\n",
      "image_encoder.layers.3.blocks.0.local_conv.bn.weight\n",
      "image_encoder.layers.3.blocks.0.local_conv.bn.bias\n",
      "image_encoder.layers.3.blocks.0.local_conv.bn.running_mean\n",
      "image_encoder.layers.3.blocks.0.local_conv.bn.running_var\n",
      "image_encoder.layers.3.blocks.0.local_conv.bn.num_batches_tracked\n",
      "image_encoder.layers.3.blocks.1.attn.attention_biases\n",
      "image_encoder.layers.3.blocks.1.attn.norm.weight\n",
      "image_encoder.layers.3.blocks.1.attn.norm.bias\n",
      "image_encoder.layers.3.blocks.1.attn.qkv.weight\n",
      "image_encoder.layers.3.blocks.1.attn.qkv.bias\n",
      "image_encoder.layers.3.blocks.1.attn.proj.weight\n",
      "image_encoder.layers.3.blocks.1.attn.proj.bias\n",
      "image_encoder.layers.3.blocks.1.mlp.norm.weight\n",
      "image_encoder.layers.3.blocks.1.mlp.norm.bias\n",
      "image_encoder.layers.3.blocks.1.mlp.fc1.weight\n",
      "image_encoder.layers.3.blocks.1.mlp.fc1.bias\n",
      "image_encoder.layers.3.blocks.1.mlp.fc2.weight\n",
      "image_encoder.layers.3.blocks.1.mlp.fc2.bias\n",
      "image_encoder.layers.3.blocks.1.local_conv.c.weight\n",
      "image_encoder.layers.3.blocks.1.local_conv.bn.weight\n",
      "image_encoder.layers.3.blocks.1.local_conv.bn.bias\n",
      "image_encoder.layers.3.blocks.1.local_conv.bn.running_mean\n",
      "image_encoder.layers.3.blocks.1.local_conv.bn.running_var\n",
      "image_encoder.layers.3.blocks.1.local_conv.bn.num_batches_tracked\n",
      "image_encoder.norm_head.weight\n",
      "image_encoder.norm_head.bias\n",
      "image_encoder.head.weight\n",
      "image_encoder.head.bias\n",
      "image_encoder.neck.0.weight\n",
      "image_encoder.neck.1.weight\n",
      "image_encoder.neck.1.bias\n",
      "image_encoder.neck.2.weight\n",
      "image_encoder.neck.3.weight\n",
      "image_encoder.neck.3.bias\n",
      "prompt_encoder.pe_layer.positional_encoding_gaussian_matrix\n",
      "prompt_encoder.point_embeddings.0.weight\n",
      "prompt_encoder.point_embeddings.1.weight\n",
      "prompt_encoder.point_embeddings.2.weight\n",
      "prompt_encoder.point_embeddings.3.weight\n",
      "prompt_encoder.point_embeddings.4.weight\n",
      "prompt_encoder.not_a_point_embed.weight\n",
      "prompt_encoder.mask_downscaling.0.weight\n",
      "prompt_encoder.mask_downscaling.0.bias\n",
      "prompt_encoder.mask_downscaling.1.weight\n",
      "prompt_encoder.mask_downscaling.1.bias\n",
      "prompt_encoder.mask_downscaling.3.weight\n",
      "prompt_encoder.mask_downscaling.3.bias\n",
      "prompt_encoder.mask_downscaling.4.weight\n",
      "prompt_encoder.mask_downscaling.4.bias\n",
      "prompt_encoder.mask_downscaling.6.weight\n",
      "prompt_encoder.mask_downscaling.6.bias\n",
      "prompt_encoder.no_mask_embed.weight\n",
      "mask_decoder.transformer.layers.0.self_attn.q_proj.bias\n",
      "mask_decoder.transformer.layers.0.self_attn.q_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.0.self_attn.q_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.0.self_attn.q_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.0.self_attn.q_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.0.self_attn.k_proj.bias\n",
      "mask_decoder.transformer.layers.0.self_attn.k_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.0.self_attn.k_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.0.self_attn.k_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.0.self_attn.k_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.0.self_attn.v_proj.bias\n",
      "mask_decoder.transformer.layers.0.self_attn.v_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.0.self_attn.v_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.0.self_attn.v_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.0.self_attn.v_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.0.self_attn.out_proj.bias\n",
      "mask_decoder.transformer.layers.0.self_attn.out_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.0.self_attn.out_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.0.self_attn.out_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.0.self_attn.out_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.0.norm1.weight\n",
      "mask_decoder.transformer.layers.0.norm1.bias\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.0.norm2.weight\n",
      "mask_decoder.transformer.layers.0.norm2.bias\n",
      "mask_decoder.transformer.layers.0.mlp.lin1.bias\n",
      "mask_decoder.transformer.layers.0.mlp.lin1.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.0.mlp.lin1.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.0.mlp.lin1.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.0.mlp.lin1.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.0.mlp.lin2.bias\n",
      "mask_decoder.transformer.layers.0.mlp.lin2.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.0.mlp.lin2.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.0.mlp.lin2.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.0.mlp.lin2.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.0.norm3.weight\n",
      "mask_decoder.transformer.layers.0.norm3.bias\n",
      "mask_decoder.transformer.layers.0.norm4.weight\n",
      "mask_decoder.transformer.layers.0.norm4.bias\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.1.self_attn.q_proj.bias\n",
      "mask_decoder.transformer.layers.1.self_attn.q_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.1.self_attn.q_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.1.self_attn.q_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.1.self_attn.q_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.1.self_attn.k_proj.bias\n",
      "mask_decoder.transformer.layers.1.self_attn.k_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.1.self_attn.k_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.1.self_attn.k_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.1.self_attn.k_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.1.self_attn.v_proj.bias\n",
      "mask_decoder.transformer.layers.1.self_attn.v_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.1.self_attn.v_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.1.self_attn.v_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.1.self_attn.v_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.1.self_attn.out_proj.bias\n",
      "mask_decoder.transformer.layers.1.self_attn.out_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.1.self_attn.out_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.1.self_attn.out_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.1.self_attn.out_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.1.norm1.weight\n",
      "mask_decoder.transformer.layers.1.norm1.bias\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.1.norm2.weight\n",
      "mask_decoder.transformer.layers.1.norm2.bias\n",
      "mask_decoder.transformer.layers.1.mlp.lin1.bias\n",
      "mask_decoder.transformer.layers.1.mlp.lin1.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.1.mlp.lin1.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.1.mlp.lin1.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.1.mlp.lin1.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.1.mlp.lin2.bias\n",
      "mask_decoder.transformer.layers.1.mlp.lin2.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.1.mlp.lin2.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.1.mlp.lin2.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.1.mlp.lin2.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.1.norm3.weight\n",
      "mask_decoder.transformer.layers.1.norm3.bias\n",
      "mask_decoder.transformer.layers.1.norm4.weight\n",
      "mask_decoder.transformer.layers.1.norm4.bias\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.final_attn_token_to_image.q_proj.bias\n",
      "mask_decoder.transformer.final_attn_token_to_image.q_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.final_attn_token_to_image.q_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.final_attn_token_to_image.q_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.final_attn_token_to_image.q_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.final_attn_token_to_image.k_proj.bias\n",
      "mask_decoder.transformer.final_attn_token_to_image.k_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.final_attn_token_to_image.k_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.final_attn_token_to_image.k_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.final_attn_token_to_image.k_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.final_attn_token_to_image.v_proj.bias\n",
      "mask_decoder.transformer.final_attn_token_to_image.v_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.final_attn_token_to_image.v_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.final_attn_token_to_image.v_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.final_attn_token_to_image.v_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.final_attn_token_to_image.out_proj.bias\n",
      "mask_decoder.transformer.final_attn_token_to_image.out_proj.parametrizations.weight.original\n",
      "mask_decoder.transformer.final_attn_token_to_image.out_proj.parametrizations.weight.0.lora_A\n",
      "mask_decoder.transformer.final_attn_token_to_image.out_proj.parametrizations.weight.0.lora_B\n",
      "mask_decoder.transformer.final_attn_token_to_image.out_proj.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.transformer.norm_final_attn.weight\n",
      "mask_decoder.transformer.norm_final_attn.bias\n",
      "mask_decoder.iou_token.weight\n",
      "mask_decoder.mask_tokens.weight\n",
      "mask_decoder.output_upscaling.0.weight\n",
      "mask_decoder.output_upscaling.0.bias\n",
      "mask_decoder.output_upscaling.1.weight\n",
      "mask_decoder.output_upscaling.1.bias\n",
      "mask_decoder.output_upscaling.3.weight\n",
      "mask_decoder.output_upscaling.3.bias\n",
      "mask_decoder.output_hypernetworks_mlps.0.layers.0.bias\n",
      "mask_decoder.output_hypernetworks_mlps.0.layers.0.parametrizations.weight.original\n",
      "mask_decoder.output_hypernetworks_mlps.0.layers.0.parametrizations.weight.0.lora_A\n",
      "mask_decoder.output_hypernetworks_mlps.0.layers.0.parametrizations.weight.0.lora_B\n",
      "mask_decoder.output_hypernetworks_mlps.0.layers.0.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.output_hypernetworks_mlps.0.layers.1.bias\n",
      "mask_decoder.output_hypernetworks_mlps.0.layers.1.parametrizations.weight.original\n",
      "mask_decoder.output_hypernetworks_mlps.0.layers.1.parametrizations.weight.0.lora_A\n",
      "mask_decoder.output_hypernetworks_mlps.0.layers.1.parametrizations.weight.0.lora_B\n",
      "mask_decoder.output_hypernetworks_mlps.0.layers.1.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.output_hypernetworks_mlps.0.layers.2.bias\n",
      "mask_decoder.output_hypernetworks_mlps.0.layers.2.parametrizations.weight.original\n",
      "mask_decoder.output_hypernetworks_mlps.0.layers.2.parametrizations.weight.0.lora_A\n",
      "mask_decoder.output_hypernetworks_mlps.0.layers.2.parametrizations.weight.0.lora_B\n",
      "mask_decoder.output_hypernetworks_mlps.0.layers.2.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.0.bias\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.0.parametrizations.weight.original\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.0.parametrizations.weight.0.lora_A\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.0.parametrizations.weight.0.lora_B\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.0.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.1.bias\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.1.parametrizations.weight.original\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.1.parametrizations.weight.0.lora_A\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.1.parametrizations.weight.0.lora_B\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.1.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.2.bias\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.2.parametrizations.weight.original\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.2.parametrizations.weight.0.lora_A\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.2.parametrizations.weight.0.lora_B\n",
      "mask_decoder.output_hypernetworks_mlps.1.layers.2.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.0.bias\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.0.parametrizations.weight.original\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.0.parametrizations.weight.0.lora_A\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.0.parametrizations.weight.0.lora_B\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.0.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.1.bias\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.1.parametrizations.weight.original\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.1.parametrizations.weight.0.lora_A\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.1.parametrizations.weight.0.lora_B\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.1.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.2.bias\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.2.parametrizations.weight.original\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.2.parametrizations.weight.0.lora_A\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.2.parametrizations.weight.0.lora_B\n",
      "mask_decoder.output_hypernetworks_mlps.2.layers.2.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.0.bias\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.0.parametrizations.weight.original\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.0.parametrizations.weight.0.lora_A\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.0.parametrizations.weight.0.lora_B\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.0.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.1.bias\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.1.parametrizations.weight.original\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.1.parametrizations.weight.0.lora_A\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.1.parametrizations.weight.0.lora_B\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.1.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.2.bias\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.2.parametrizations.weight.original\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.2.parametrizations.weight.0.lora_A\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.2.parametrizations.weight.0.lora_B\n",
      "mask_decoder.output_hypernetworks_mlps.3.layers.2.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.iou_prediction_head.layers.0.bias\n",
      "mask_decoder.iou_prediction_head.layers.0.parametrizations.weight.original\n",
      "mask_decoder.iou_prediction_head.layers.0.parametrizations.weight.0.lora_A\n",
      "mask_decoder.iou_prediction_head.layers.0.parametrizations.weight.0.lora_B\n",
      "mask_decoder.iou_prediction_head.layers.0.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.iou_prediction_head.layers.1.bias\n",
      "mask_decoder.iou_prediction_head.layers.1.parametrizations.weight.original\n",
      "mask_decoder.iou_prediction_head.layers.1.parametrizations.weight.0.lora_A\n",
      "mask_decoder.iou_prediction_head.layers.1.parametrizations.weight.0.lora_B\n",
      "mask_decoder.iou_prediction_head.layers.1.parametrizations.weight.0.lora_dropout_mask\n",
      "mask_decoder.iou_prediction_head.layers.2.bias\n",
      "mask_decoder.iou_prediction_head.layers.2.parametrizations.weight.original\n",
      "mask_decoder.iou_prediction_head.layers.2.parametrizations.weight.0.lora_A\n",
      "mask_decoder.iou_prediction_head.layers.2.parametrizations.weight.0.lora_B\n",
      "mask_decoder.iou_prediction_head.layers.2.parametrizations.weight.0.lora_dropout_mask\n"
     ]
    }
   ],
   "source": [
    "for i in l.keys():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 256])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l['prompt_encoder.point_embeddings.4.weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student.model.load_state_dict(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_lora(student.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(student.model.state_dict(), 'merged.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018324607329842892"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(3.82 - 3.75) / 3.82"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
