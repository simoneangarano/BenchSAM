{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from step_2.datasets import COCOSegmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDir='../Datasets/coco-2017/'\n",
    "dataType='val2017'\n",
    "annFile='{}/annotations/instances_{}.json'.format(dataDir,dataType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = COCOSegmentation(dataDir, 'val', crop_size=0)\n",
    "dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False, num_workers=4, pin_memory=True, worker_init_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, l, n = dataset[0]\n",
    "i.shape, l.shape, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (i, l, n) in dataloader:\n",
    "    print(i.shape, l.shape, n)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(i[0])\n",
    "plt.imshow(l[0], alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "l.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from mobile_sam import sam_model_registry, SamPredictor\n",
    "\n",
    "from step_2.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "GPU = 3\n",
    "\n",
    "device = torch.device(f\"cuda:{GPU}\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"vit_t\"\n",
    "sam_checkpoint = \"bin/mobile_sam.pt\"\n",
    "\n",
    "model = sam_model_registry[model_type](checkpoint=sam_checkpoint).to(device).eval()\n",
    "predictor = SamPredictor(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Input Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_url = \"https://huggingface.co/ybelkada/segment-anything/resolve/main/assets/car.png\"\n",
    "raw_image = np.array(Image.open(requests.get(img_url, stream=True).raw).convert(\"RGB\"))\n",
    "# plt.imshow(raw_image)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Inference with Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_points = np.array([[450, 600]])\n",
    "input_label = np.array([1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_points = np.array([[450, 600]])\n",
    "input_label = np.array([1])\n",
    "\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictor.set_image(raw_image)\n",
    "    masks, scores, _ = predictor.predict(input_points, input_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(raw_image)\n",
    "plt.imshow(masks[0], alpha=0.5)\n",
    "plt.imshow(masks[1], alpha=0.5)\n",
    "plt.imshow(masks[2], alpha=0.5)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decode Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(masks[np.argmax(scores)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CENTER = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output_masks(processor, model, i, input_points, device):\n",
    "    i = i[0].detach().cpu().numpy().astype(np.uint8)\n",
    "    predictor.set_image(i)\n",
    "    masks, scores, _ = predictor.predict(np.array(input_points[0]), np.array([1]))\n",
    "    return masks, scores\n",
    "    \n",
    "def get_prompt(name, label):\n",
    "\n",
    "    # Load_prompts missing\n",
    "\n",
    "    C = np.unique(label)[1:]\n",
    "    c = np.random.choice(C)\n",
    "\n",
    "    if CENTER:\n",
    "        x, y = torch.sum(torch.argwhere(label==c),0)/torch.sum(label==c).detach().cpu().numpy()\n",
    "        x, y = int(x), int(y)\n",
    "    else:\n",
    "        x_v, y_v = np.where(label == c)\n",
    "        r = random.randint(0,len(x_v))\n",
    "        x, y = x_v[r], y_v[r]\n",
    "    return [[[y,x]]], c # inverted to compensate different indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_masks():\n",
    "\n",
    "    name_list, mask_list, score_list, prompt_list, p_class_list = [], [], [], [], []\n",
    "    for j, (i, l, n) in enumerate(dataloader):\n",
    "\n",
    "        prompt, p_class = get_prompt(n, l[0])\n",
    "        # show_points_on_image(i[0], input_points[0])\n",
    "\n",
    "        masks, scores = get_output_masks(None, predictor, i, prompt, device)\n",
    "        # show_masks_on_image(i[0], masks, scores)  \n",
    "        name_list.append(int(n[0]))\n",
    "        mask_list.append(masks.squeeze()[scores.argmax()])\n",
    "        score_list.append(float(scores.max()))\n",
    "        prompt_list.append(prompt[0][0])\n",
    "        p_class_list.append(int(p_class))\n",
    "\n",
    "        if j > 1:\n",
    "            break\n",
    "\n",
    "    return name_list, prompt_list, p_class_list, mask_list, score_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name, prompt, p_class, mask, score = get_masks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "name[i], prompt[i], p_class[i], mask[i].shape, score[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = Image.open('../Datasets/coco-2017/val2017/' + str(name[i]).zfill(12) + '.jpg')\n",
    "plt.imshow(im)\n",
    "plt.imshow(mask[i], alpha=0.5)\n",
    "print(dataset.classes[p_class[i]])\n",
    "print(name[i])\n",
    "plt.scatter(*prompt[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'name': name, 'prompt': prompt, 'class': p_class, 'mask': mask, 'score': score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist(column='class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['name', 'point', 'class']].to_pickle(\"results/coco_prompts.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['name', 'point', 'class']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"results/cityscapes_prompts.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['name']==632][['point', 'class']].values[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicted Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 92"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_instance(label, c=None):\n",
    "    if c is None:\n",
    "        C = np.unique(label)[1:]\n",
    "        c = np.random.choice(C)\n",
    "        return label == c, c\n",
    "    else:\n",
    "        return label == c, c\n",
    "\n",
    "def get_pred_classes(inst, label, n_classes, threshold=0.01):\n",
    "    im = torch.logical_not(inst).to(torch.uint8)\n",
    "    im[im==1] = n_classes\n",
    "    m = im + label\n",
    "    h, _ = np.histogram(m, bins=256, range=(0,255))\n",
    "    clean_h = h[:n_classes]\n",
    "    mask_tot = np.sum(clean_h)\n",
    "    classes = np.where(clean_h > threshold * mask_tot)[0]\n",
    "    return list(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test class threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label\n",
    "l = torch.zeros((224,224), dtype=torch.uint8)\n",
    "l[100:150, 50:100] = 35\n",
    "l[145:150, 95:100] = 91\n",
    "l[100:140, 160:200] = 60\n",
    "l[100:115, 50:65] = 0\n",
    "\n",
    "plt.imshow(l)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted instance\n",
    "i = torch.zeros((224,224), dtype=bool)\n",
    "i[100:150, 50:100] = True\n",
    "plt.imshow(i)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_pred_classes(i, l, N_CLASSES, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modified instance\n",
    "im = torch.logical_not(i).to(torch.uint8)\n",
    "im[im==1] = N_CLASSES\n",
    "\n",
    "plt.imshow(im)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im.min(), im.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mask (intersection)\n",
    "m = im + l\n",
    "\n",
    "plt.imshow(m)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h, _ = np.histogram(m, bins=256, range=(0,255))\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_h = h[:N_CLASSES]\n",
    "clean_h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_tot = np.sum(clean_h)\n",
    "mask_tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(clean_h > 0.01 * mask_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from step_2.utils import show_points_and_masks_on_image\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = ''\n",
    "DATASET = 'coco'\n",
    "MODEL = 'FastSAM'\n",
    "ROOT = Path(\"../Datasets/coco-2017/val2017/\") if DATASET == 'coco' else Path(\"../Datasets/Cityscapes/leftImg8bit/val/\")\n",
    "SPARSITY = 50\n",
    "CLASSES = ['background', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant',\n",
    "           'street sign', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', \n",
    "           'hat', 'backpack', 'umbrella', 'shoe', 'eye glasses', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports', 'kite', \n",
    "           'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'plate', 'wine glass', 'cup', 'fork', 'knife', \n",
    "           'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "           'potted plant', 'bed', 'mirror', 'dining table', 'window', 'desk', 'toilet', 'door', 'tv', 'laptop', 'mouse', 'remote', 'keyboard',\n",
    "           'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'blender', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "           'hair drier', 'toothbrush', 'hair brush']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(target, pred, eps=1e-5, verbose=False):\n",
    "\n",
    "    if verbose:\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(target)\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(pred)\n",
    "        plt.show()\n",
    "\n",
    "    output = np.reshape(pred, -1)\n",
    "    target = np.reshape(target, -1)\n",
    "\n",
    "    tp = np.sum(output * target)  # TP (Intersection)\n",
    "    un = np.sum(output + target)  # Union\n",
    "    fp = np.sum(output * (~target))  # FP\n",
    "    fn = np.sum((~output) * target)  # FN\n",
    "    tn = np.sum((~output) * (~target))  # TN\n",
    "\n",
    "    iou = (tp + eps) / (un + eps)\n",
    "    pixel_acc = (tp + tn + eps) / (tp + tn + fp + fn + eps)\n",
    "    dice = (2 * tp + eps) / (2 * tp + fp + fn + eps)\n",
    "    precision = (tp + eps) / (tp + fp + eps)\n",
    "    recall = (tp + eps) / (tp + fn + eps)\n",
    "    specificity = (tn + eps) / (tn + fp + eps)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"IoU: {iou:.4f}, Pixel Acc: {pixel_acc:.4f}, Dice: {dice:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}, Specificity: {specificity:.4f}\")\n",
    "\n",
    "    return iou, pixel_acc, dice, precision, specificity, recall\n",
    "\n",
    "def get_analytics(target_df, pred_df):\n",
    "    metrics = {k: [] for k in ['name', 'prompt', 'class', 't_class', 's_class', 'score', 'score_diff', 'mask_size', \n",
    "                               'mask_size_diff', 'iou', 'pixel_acc', 'dice', 'precision', 'recall', 'specificity']}\n",
    "    for i in range(len(target_df)):\n",
    "        target = target_df.loc[i]\n",
    "        pred = pred_df.loc[i]\n",
    "\n",
    "        iou, pixel_acc, dice, precision, specificity, recall = calculate_metrics(target['mask'], pred['mask'])\n",
    "        \n",
    "        metrics['name'].append(target['name'])\n",
    "        metrics['prompt'].append(target['prompt'])\n",
    "        metrics['class'].append(target['class'])\n",
    "        metrics['t_class'].append(target['s_class'])\n",
    "        metrics['s_class'].append(pred['s_class'])\n",
    "        metrics['score'].append(pred['score'])\n",
    "        metrics['score_diff'].append((pred['score'] - target['score']) / (target['score'] + 1e-5))\n",
    "        p_size = np.mean(pred['mask'].astype('float'))\n",
    "        t_size = np.mean(target['mask'].astype('float'))\n",
    "        metrics['mask_size'].append(p_size)\n",
    "        metrics['mask_size_diff'].append((p_size - t_size) / (t_size + 1e-3))\n",
    "        metrics['iou'].append(iou)\n",
    "        metrics['pixel_acc'].append(pixel_acc)\n",
    "        metrics['dice'].append(dice)\n",
    "        metrics['precision'].append(precision)\n",
    "        metrics['recall'].append(recall)\n",
    "        metrics['specificity'].append(specificity)\n",
    "    \n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "def get_labels(name):\n",
    "    if isinstance(name, list):\n",
    "        return [get_labels(n) for n in name]\n",
    "    else: \n",
    "        return CLASSES[name].title()\n",
    "\n",
    "def get_image(name):\n",
    "    if DATASET == 'coco':\n",
    "        image_path = ROOT.joinpath(f'{str(name).zfill(12)}.jpg')\n",
    "    else:\n",
    "        image_path = ROOT.joinpath(f\"{name.split('_')[0]}/{name}\")\n",
    "    return np.array(Image.open(image_path).convert(\"RGB\"))\n",
    "\n",
    "def show_entry(row, target_df, pred_df):\n",
    "    image = get_image(row['name'])\n",
    "    target_mask = target_df[target_df['name']==row['name']]['mask'].values[0]\n",
    "    pred_mask = pred_df[pred_df['name']==row['name']]['mask'].values[0]\n",
    "    show_points_and_masks_on_image(image, [pred_mask, target_mask], [row['prompt']])\n",
    "    print(f'ID: {row[\"name\"]}, PromptClass: {get_labels(row[\"class\"])}, TargetClass: {get_labels(row[\"t_class\"])}, PredClass: {get_labels(row[\"s_class\"])},') \n",
    "    print(f'ScoreDiff: {row[\"score_diff\"]:.4f}, MaskSizeDiff: {row[\"mask_size_diff\"]:.4f}, IoU: {row[\"iou\"]:.4f}')\n",
    "    \n",
    "def show_samples(pie_df, target_df, pred_df, n=5):\n",
    "    print('Legend: Target -> Orange, Prediction -> Blue')\n",
    "    pie_df.iloc[:n].apply(lambda x: show_entry(x, target_df, pred_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.read_pickle(f\"results/{EXPERIMENT}{DATASET}_prompts.pkl\")\n",
    "df_0 = pd.read_pickle(f\"results/{EXPERIMENT}{DATASET}_SAM_0.pkl\")\n",
    "df_s = pd.read_pickle(f\"results/{EXPERIMENT}{DATASET}_{MODEL}_0.pkl\")\n",
    "df_0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0s = get_analytics(df_0, df_s)\n",
    "df_0s.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_size = df_0s.nsmallest(25, ['mask_size_diff'])\n",
    "max_size = df_0s.nlargest(25, ['mask_size_diff'])\n",
    "min_score = df_0s.nsmallest(25, ['score_diff']) # not very useful\n",
    "max_score = df_0s.nlargest(25, ['score_diff']) # not very useful\n",
    "min_iou = df_0s.nsmallest(25, ['iou'])\n",
    "max_iou = df_0s.nlargest(25, ['iou'])\n",
    "min_size.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iou.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_samples(min_size, df_0, df_s, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s[df_s['score']<=0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_s.hist(column='score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = torch.zeros((224,224), dtype=bool)\n",
    "o = torch.ones((50,50), dtype=bool)\n",
    "m[100:150, :50] = o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(m)\n",
    "x, y = torch.argwhere(m==1).sum(0)/torch.sum(m)\n",
    "x, y = int(x), int(y)\n",
    "print(x, y)\n",
    "plt.scatter(y, x, color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
